% Yay, the article for the end of this year, in LaTeX.

\documentclass[a4paper, 12pt]{article}

\newcommand{\ffi}{\Leftrightarrow}
\newcommand{\imply}{\Rightarrow}


\usepackage[french]{babel}
\usepackage{listings}
\usepackage{fancyhdr, fancybox}
\usepackage{amsmath, amssymb}
\usepackage{xcolor, changepage, array, placeins, float, verbatim}
\usepackage{qtree, forest}
\usepackage[utf8]{inputenc}
\usepackage{listingsutf8}
\pagestyle{fancy}

\definecolor{codecomments}{HTML}{FFA700}
\definecolor{codenumbers}{HTML}{D62D20}
\definecolor{codestrings}{HTML}{008744}
% \definecolor{backcolour}{HTML}{F7F7F7}
\definecolor{keycolor}{HTML}{3B5998}%{0057E7}
\definecolor{backcolour}{HTML}{FFFFFF}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codecomments},
    keywordstyle=\color{keycolor},
    numberstyle=\tiny\color{codenumbers},
    stringstyle=\color{codestrings},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbersep=5pt,
    showspaces=false,
    xleftmargin=\parindent,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    rulecolor=\color{black},
    frame=L
  }

\lstset{
    style=mystyle,
    morecomment=[s][\color{codenumbers}]{@}{\ },
    extendedchars=true,
    literate={√©}{{\'e}}1
    {√¢}{{\^a}}1
    {√†}{{\`a}}1
    {√™}{{\^e}}1
    {√®}{{\`e}}1
    {√Æ}{{\^i}}1
    {0}{{{\color{codenumbers}0}}}1
    {1}{{{\color{codenumbers}1}}}1
    {2}{{{\color{codenumbers}2}}}1
    {3}{{{\color{codenumbers}3}}}1
    {4}{{{\color{codenumbers}4}}}1
    {5}{{{\color{codenumbers}5}}}1
    {6}{{{\color{codenumbers}6}}}1
    {7}{{{\color{codenumbers}7}}}1
    {8}{{{\color{codenumbers}8}}}1
    {9}{{{\color{codenumbers}9}}}1
    {1-}{{{\color{codenumbers}1-}}}2
    {1+}{{{\color{codenumbers}1+}}}2
    {remove-if}{{{\color{keycolor}remove-if}}}8
    {if}{{{\color{keycolor}if}}}2
    {True}{{{\color{teal}True}}}4
    {False}{{{\color{teal}False}}}4
    {await}{{{\color{keycolor}await}}}5
    {\ as\ }{{{\color{keycolor}as}}}4
    {async\ }{{{\color{keycolor}async}}}5
  }
\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\sectionmark}[ 1 ]{\markboth{\thesection. #1 }{ }}
\renewcommand{\subsectionmark}[ 1 ]{\markright{\thesubsection. #1 }}

\renewcommand{\labelenumi}{\alph{enumi}.}
\renewcommand{\theenumi}{\alph{enumi}.}
\renewcommand{\labelenumii}{\roman{enumii}.}
\renewcommand{\theenumii}{\roman{enumii}.}

\rhead[\textbf{}]{\textbf{}}
\lhead[\textbf{}]{\textbf{}}
\lfoot[{\bf \thepage}]{{\bf \thepage}}
\rfoot[{\bf \thepage}]{\textbf{IA PAS DE SOUCIS!}}
\cfoot[]{}

\numberwithin{equation}{subsection}
\renewcommand{\headrulewidth}{ 0.15 mm}
\renewcommand{\footrulewidth}{ 0.15 mm}
\addtolength{\headwidth}{\marginparsep}
\addtolength{\headwidth}{\marginparwidth}

\newcolumntype{M}[ 1 ]{>{\centering\arraybackslash}m{#1}}

\title{IA Pas de Soucis!}
\author{Un projet de Evrard Maurice,\\ Lejeune Gr√©gory,\\ Lejeune Lucas \\ Mathieu Louca,\\ Pluvinage Victor\\ et de Ralet Vincent.}

\begin{document}
\maketitle
\newpage

\section{Histoire.}

\section{L'approche logique.}
\subsection{Les bases de la logique}
\subsection{Origines.}
Avant les premi√®res d√©couvertes scientifiques concernant l'intelligence, elle est d√©j√† notemment imagin√©e dans des oeuvres de fiction dans lesquelles des des artisans seraient capables de mettre au point des √™tres artificiels dot√©s d'une intelligence. Certains de ces √™tres artificiels verront le jour sous la forme d'automates (Ex: Automates de Vaucanson, 18e si√®cle).\\

L'intelligence artificielle comme nous la connaissons aujourd'hui a d'abord √©t√© pr√©sent√©e par des philosphes de l'√®re classique, Leibniz par exemple. Ils avan√ßaient que la pens√©e humaine √©tait un raisonnement m√©canique explicable par les math√©matiques. Ils n'ont cependant jamais tent√© de cr√©er une intelligence artificielle.\\

Entre les ann√©es 1930 et 1950 de nombreux progr√®s sont faits en neurologie, on comprend que le cerveau est un r√©seau de neurones qui envoient un signal √©lectrique binaire (c.f. Th√©orie de l'information de Claude Shannon). La th√©orie du calcul d'Alan Turing montre que toute forme de calculpeut √™tre repr√©sent√©e num√©riquement. Addition√©s au travail de Norbert Wiener sur la cybern√©tique, ces progr√®s poussent la communaut√© scientifique √† croire en la possibilit√© de construire un cerveau artificiel.
\subsection{Arriv√©e des premiers ordinateurs.}
Les premiers ordinateurs modernes feront leur apparition durant la seconde guerre mondiale pouss√©s par la qu√™te d'informations prot√©g√©es par des codes sur les strat√©gies des diff√©rents camps.
\subsubsection{Premi√®res concr√©tisations d'intelligences artificielles:}
\begin{enumerate}
  \item En 1949, Warren Weaver met au point un protocole qui vise √† utiliser l'intelligence artificielle pour traduire automatiquement diff√©rents langages.
  \item En 1950, Alan Turing publie un article dans lequel il imaginera le c√©l√®bre \textit{Test de Turing} qui vise √† d√©finir ce qui est ou non une machine intelligente. Pour se faire, la machine doit pouvoir converser avec un humain sans que ce dernier se rende compte de sa vraie nature. Il sera r√©ussi pour la premi√®re fois dans les ann√©es 60 par ELIZA, une IA simulant un psychoth√©rapeute. Elle se contentait en r√©alit√© de reformuler les affirmations du ``patient ''en questions.
  \item En 1955, Allen Newell accompagn√© de Herbert Simon de de Cliff Shaw cr√©e le \textit{Th√©oricien logique}, un programme capable de d√©montrer 38 des 52 premiers th√©or√®mes des \textit{Principia Mathematica} de Russell et Whitehead, et a m√™me trouv√© des d√©monstrations in√©dites et √©l√©gantes.
\end{enumerate}
\subsection{Officialisation.}
En 1956 la conf√©rence de Dartmouth r√©unit tout les plus grand scientifiques travaillant alors sur le sujet de l'intelligence artificielle. Elle est le vrai point de d√©part de l'intelligence artificielle moderne √©tant donn√© que c'est √† ce moment qu'elle a d√©fini ses objectifs et qu'elle devient officiellement une discipline scientifique.
\subsection{L'√¢ge d'or (1956-1974).}
La conf√©rence de Dartmouth marque le d√©but de l'√¢ge d'or de l'IA. En effet, entre 1956 et 1974 l'IA va voir un grand nombre de d√©couvertes qui pousseront les investissements, ce qui entrainera un cercle vertueux. Cett p√©riode sera donc marqu√©e par un optimisme presque excessif concernant les ``futurs'' progr√®s de L'IA.\\

La m√©thode alors utilis√©e par la grande majorit√© des programmes consiste √† avancer pas √† pas en faisant des essais-erreurs. Cette m√©thode montrera toutefois ses limites face aux \textit{explosions combinatoires} (probl√®mes dont le nombre de chemins possibles vers une solution est astronomique).
\subsection{L'hiver de l'IA (1974-1980).}
L'ann√©e 1974 marque le d√©but de la p√©riode creuse de l'histoire de l'intelligence artificielle. Cela est du au retour √† la r√©alit√© des chercheurs en IA qui se retrouvaient face √† des impasses, limit√©s par le niveau technologique de l'√©poque. Cette baisse de vitesses dans les d√©couvertes accompagn√©e de nombreuses critiques concernant les recherches men√©es jusqu'alors provoquera la d√©ception et le retrait de nombreux investisseurs optimistes.\\

Cette p√©riode marque malgr√© tout l'introduction de la logique dans l'IA, notemment par l'invention du langage de programmation Prolog
\subsection{Le retour en force (1980-1987).}
Cette p√©riode voit apparaitre un nouveau genre de programmes d'IA appel√© ``Syst√®mes experts'', ces programmes ont pour particularit√©s d'√™tre limit√©s √† de domaines tr√®s restreints. En effet, ils utilisent un ensemble de r√®gles logiques qui prennent sources dans les connaissances des experts humains de son domaine. Cette limite volontaire impos√©e √† ces programmes les rendent plus facile √† ocncevoir et √† am√©liorer une fois d√©ploy√©s. Ces programmes sont les premiers √† r√©ellement se rendre utiles pour la soci√©t√©.\\

Le gouvernement japonais va permettre √† l'IA de se relancer √©conomiquement en investissant 850 millions de Dollars dans le but de d√©velopper des programmes de communication (Traduction, interpr√©tation d'images,...). Le Royaume)Uni lance un projet similaire qu'il finance √† hauteur de 350 millions de livres.
\subsection{Le nouvel hiver (1987-1993).}
L'engouement qu'avait r√©ussi √† cr√©er l'IA au d√©but des ann√©es 80 gr√¢ce aux syst√®mes experts a en fait cr√©√© une bulle √©conomique qui a fini par exploser √† leur fin.\\
Cette p√©riode marquera tout de m√™me l'appartition d'une nouvelle approche de l'IA, une approche dans laquelle les intelligences artifielles devraient avoir conscience de ``leur corps'' et de l'environnement qui les entoure.
\subsection{Depuis 1993.}
Gr√¢ce √† un niveau technologique et donc une puissance de calcul qui augmente de mani√®re exponentielle (c.f. Loi de Moore), de nombreux objectifs de l'IA. Les investissements n'affluent toujours pas car on ne s'est pas encore approch√© du tout du r√™ve des ann√©es 60, c'est √† dire une IA aussi intelligente qu'un humain.\\

Depuis 1993 l'IA continue de faire ses preuves aux travers de nombreux exploits, on peut noter la victoire historique de l'IA Deep Blue aux √©checs contre le champion du monde en titre des √©checs Garry Kasparov. On peut aussi parler des nombreux robots antropomorphes comme le Asimo de Honda ou les robots militaires de Boston Dynamics dont les capacit√©s ne cessent d'impressioner le grand public. Mais au del√† de ces prouesses l'intelligence artificielle a aujourd'hui surtout gagn√© une place pro√©iminente dans notre quotidien: applis de traduction, publicit√©s cibl√©es, GPS, recommandations d'amis sur les r√©seaux sociaux, ... .
\newpage
\section{L'Approche Logique.}
\subsection{Les bases de la logique}
  \subsubsection{Introduction √† la logique propositionnelle.}
     L'importance de la logique propositionnelle est immense en math√©matiques et en cryptographie, mais √©galement, comme nous allons le voir, en informatique.\\
     Voici une fameuse lapalissade, exemple typique d'utilisation d'une phrase ne d√©coulant de rien d'autre que de cette logique:
  \begin{center}
    \shadowbox{{\bf ''15 minutes avant sa mort, il √©tait encore en vie.''}\footnotemark} \footnotetext{ https://fr.wikipedia.org/wiki/Lapalissade}
  \end{center}
     √âvidemment, gr√¢ce √† notre capacit√© d√©ductionnelle, nous pouvons tous d√©finir cette phrase comme vraie, c'est ici, une v√©rit√© dite ``de  langage''. \\[0.5cm]

  \subsubsection{Un peu de vocabulaire!}
     La logique propositionnelle poss√®de son propre vocabulaire, il est presque indispensable de conna√Ætre son vocabulaire et sa syntaxe afin m√™me de  pouvoir en comprendre les concepts.\\
     Tout d'abord, un {\bf langage formel} est un ensemble de mots que l'on peut obtenir en utilisant un alphabet\footnote{Cela peut √™tre un alphabet comme abcd...yz tout comme un alphabet compos√© uniquement de 1 et de 0.}, un langage poss√®de plusieurs {\bf lois}, cet ensemble de lois sera appel√© la {\bf syntaxe}, qui d√©finissent les diff√©rentes mani√®res gr√¢ce auxquelles les √©l√©ments de l'alphabet (aussi appel√©s  les {\bf symboles}) peuvent se placer pour former quelque chose de coh√©rent au langage.\\ Par exemple, en fran√ßais, vous n'√©cririez pas ``J√®me lai vwaturres'', mais plut√¥t, ``j'aime les voitures'', aussi b√™te que ce petit exemple puisse para√Ætre, il s'agit  l√† de l'une des nombreuses fois o√π l'on se plie aux r√®gles d'une grammaire logique. \\
     Un mot respectant toutes les r√®gles de syntaxe sera alors appel√© un {\bf mot bien-form√©}. \\
     {\bf La logique propositionnelle} se compose donc d'un langage formel, et de s√©mantiques donnant du sens aux mots bien form√©s, r√©pondant au nom de {\bf propositions}. \\
     Les propositions logiques sont d√©sign√©es par des lettres, comme $ A, B, C$..., ou par des lettres indic√©es comme $ A_2, B_{4}$...
     Pour relier ces propositions, on utilise des connecteurs, r√©pertori√©s dans le tableau ci-dessous. \\
     \begin{table}[H]
       \centering
       \begin{tabular}{|c|c|c|}
         %!{\vrule width 0.8mm}>{\bfseries}l|
         %>{$}<{$}!{\vrule width 0.8mm}}
         \hline {\bf nom }       & {\bf symbole}     & {\bf autre nom}  \\
         \hline n√©gation         & $\neg$            & NOT              \\
         conjonction             & $\land$           & AND              \\
         disjonction (I)         & $\lor$            & OR               \\
         disjonction (E)         & $\oplus$          & XOR              \\
         implication             & $\imply$          & IF..THEN         \\
         √©quivalence             & $\ffi$            & IFF              \\
         \hline
       \end{tabular}
    \end{table}
  En plus de ces connecteurs viennent s'ajouter les deux valeurs logiques √† la base de tout, Vrai et Faux.
    \subsubsection{Pour quelques exemples de plus...}
        Voici quelques exemples d'√©nonc√©s de logique propositionnelle dans un cadre assez √©loign√© des math√©matiques, en esp√©rant que cela fasse sens au lecteur.\\
        Supposons que $A$ et $B$ soient deux propositions logiques. \\
        $A$: Je suis boulanger. \\
        $B$: Je sais faire des g√¢teaux. \\
        Nous pouvons ainsi relier ces deux propositions avec les connecteurs vus dans le tableau ci-dessus. \\
        $\neg A$: Je ne suis pas boulanger. \\
        $\neg B$: Je ne sais pas faire des g√¢teaux. \\
        $A \land B$: Je suis boulanger et je sais faire des g√¢teaux. \\
        $A \lor B$: Je suis boulanger ou je sais faire des g√¢teaux (Les deux propositions peuvent √™tre vraies, tout comme une seule des deux). \\
        $A \oplus B$: Je suis boulanger ou alors je sais faire des g√¢teaux. (Une seule de ces deux propositions doit √™tre vraie) \\
        $A \imply B$: Je suis boulanger, donc je sais faire des g√¢teaux. \\
        $A \ffi B$: Je suis boulanger si et seulement si je sais faire des g√¢teaux. \\
        ... \\
    \subsubsection{Quelques tables de v√©rit√©.}
    Apr√®s tant d'exemples ``instructifs'', il serait temps de passer aux fameuses {\bf tables de v√©rit√©}, ces tables seront d'une importance capitale lors de r√©solutions de probl√®mes, les voici donc: \
    \begin{table}[H]
      \hspace{1.0cm}
      \begin{minipage}[c]{0.1\linewidth}
        \centering
        \caption{N√©gation.}
        \label{neg_table}
      \begin{tabular}{|c|c|}
        \hline $A$ & $\neg A$ \\
        \hline  F  &     V    \\
                V  &     F    \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{2.0cm}
    \begin{minipage}[c]{0.22\linewidth}
      \centering
      \caption{\\Conjonction.}
      \label{and_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \land B$ \\
        \hline  F  &  F  &      F      \\
                F  &  V  &      F      \\
                V  &  F  &      F      \\
                V  &  V  &      V      \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.27\linewidth}
      \centering
      \caption{\\Disjonction (OR).}
      \label{or_table}
    \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \lor B$  \\
        \hline  F  &  F  &      F      \\
                F  &  V  &      V      \\
                V  &  F  &      V      \\
                V  &  V  &      V      \\
        \hline
    \end{tabular}
  \end{minipage}
  \\[1.0cm]
  \begin{minipage}[c]{0.27\linewidth}
    \centering
    \caption{\\Disjonction (XOR).}
    \label{xor_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \oplus B$ \\
        \hline  F  &  F  &       F      \\
                F  &  V  &       V      \\
                V  &  F  &       V      \\
                V  &  V  &       F      \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.22\linewidth}
      \centering
      \caption{\\Implication.}
      \label{imply_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \imply B$ \\
        \hline  F  &  F  &       V        \\
                F  &  V  &       V        \\
                V  &  F  &       F        \\
                V  &  V  &       V        \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.1\linewidth}
      \centering
      \caption{√âquivalence}
      \label{iff_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \ffi B$ \\
        \hline  F  &  F  &      V     \\
                F  &  V  &      F     \\
                V  &  F  &      F     \\
                V  &  V  &      V     \\
        \hline
      \end{tabular}
    \end{minipage}
  \end{table}
  Les tables 1 √† 4 doivent sans doute para√Ætre logique, je m'attarderai toutefois sur la table 5, en effet les deux phrases $F \imply V$ et $F \imply F$ sont toutes deux vraies.
  Cela est du au {\bf principe d'explosion}\footnote{https://fr.wikipedia.org/wiki/Principe\_d$\%$27explosion}: Du faux, on peut d√©duire absolument n'importe quoi! (On verra plus tard que l'on peut noter ceci $A \land \neg A \models B$).\\
  Pour ce qui est de la table 6, il faut savoir que certains notent $\ffi$ comme √©tant $\equiv$, cette notation a l'avantage d'accentuer le fait que cette relation n'est autre que la relation d'√©quivalence.
  \subsubsection{R√©solution de probl√®mes en logique propositionnelle.}
  Maintenant que nous avons acquis les bases de la logique propositionnelle,  attaquons nous √† quelques probl√®mes.\\
  En voici un premier,
  \begin{center}
    \Ovalbox{$ \neg (A \land B ) \ffi \neg A \lor \neg B$}
  \end{center}
Pour r√©soudre ceci, nous allons utiliser une grande table de v√©rit√©: \newpage
  \begin{table}[!t]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
      \hline $A$ & $B$ & $A \land B$ & $\neg (A \land B)$ & $\neg A$ & $\neg B$ & $\neg A \lor \neg B$ & $\neg (A \land B) \ffi \neg A \lor \neg B$ \\
      \hline  F  &  F  &      F      &          V         &     V    &     V    &          V           &                     V                      \\
              F  &  V  &      F      &          V         &     V    &     F    &          V           &                     V                      \\
              V  &  F  &      F      &          V         &     F    &     V    &          V           &                     V                      \\
              V  &  V  &      V      &          F         &     F    &     F    &          F           &                     V                      \\
      \hline
    \end{tabular}
  \end{table}
  Ainsi, comme nous pouvons le constater, la derni√®re ligne est remplie de ``V'', cela veut donc dire que nous venons de prouver la relation $\neg (A \land B) \ffi \neg A \lor \neg B$ , aussi connue sous le nom de ``la loi de DeMorgan'', nous avons prouv√© par la m√™me occasion que $\neg (A \land B) \ffi \neg A \lor B$ est {\bf valide}, cela veut dire qu'elle sera toujours vraie, peu-importe les A, et les B.\\[0.5cm]
  Il existe toutefois une autre mani√®re de faire, il s'agit d'utiliser un arbre, cette m√©thode requiert moins d'√©tapes et nous permettra de r√©soudre certains probl√®mes de mani√®re plus simple. Toutefois, il y a quelques r√®gles √† respecter lors de l'utilisation d'un arbre, ces  r√®gles sont r√©pertori√©es dans le tableau ci-dessous. \\
  \begin{center}
    \begin{table}[!hbt]
      \centering
    \begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
      \hline \begin{forest} [$\neg (\neg \phi)$ [$\phi$]]\end{forest} & \begin{forest} [$\phi \land \psi$ [$\phi$ [$\psi$]]] \end{forest} & \begin{forest} [$\neg (\psi \land \phi)$ [$\neg \psi$] [$\neg \phi$]] \end{forest} \\
     \hline \begin{forest} [$\phi \lor \psi$ [$\phi$][$\psi$]] \end{forest}& \begin{forest} [$\neg (\phi \lor \psi)$ [$\neg \phi$ [$\neg \phi$]]] \end{forest}  & \begin{forest} [$\phi \imply \psi$ [$\neg \phi$][$\psi$]] \end{forest}\\
      \hline \begin{forest} [$\neg (\phi \imply \psi)$ [$\phi$ [$\neg \psi$]]] \end{forest}& \begin{forest} [$\phi \ffi \psi$ [$\phi$ [$\psi$]] [$\neg \phi$ [$\neg \psi$]]] \end{forest}& \begin{forest} [$\neg (\phi \imply \psi)$ [$\phi$ [$\neg \psi$]] [$\neg \phi$ [$\psi$]]]\end{forest} \\
      \hline
    \end{tabular}
  \end{table}
  \end{center}
  Le but du jeu avec un arbre logique, c'est de terminer chacune des branches de l'arbre par $\bot$ (C'est le symbole utilis√© pour les contradictions). Ainsi, avec un arbre, nous commen√ßons par utiliser l'oppos√© de notre hypoth√®se de base (ici, l'oppos√© de $\neg (A \land B) \ffi \neg A \lor \neg B$, c'est $\neg (\neg (A \land B) \ffi \neg A \lor \neg B)$), (en g√©n√©ral, une contradiction arrive quand nous nous retrouvons avec $A$ et $\neg A$ sur la m√™me branche.) \\
  Passons maintenant √† la preuve
  \begin{center}
  \begin{forest}
  [$\neg (\neg (A \land B) \ffi \neg A \lor \neg B)$
    [$\neg(A \land B)$
    [$\neg (\neg A \lor \neg B)$
    [$A$
    [$B$
    [$\neg A$
    [$\bot$]]
    [$\neg B$
    [$\bot$]]]]]]
    [$\neg (\neg (A \land B))$
    [$ \neg A \lor \neg B$
    [$A \land B$
    [$A$
    [$B$
    [$\neg A$
    [$\bot$]]
    [$\neg B$
    [$\bot$]]]]]]]]
  \end{forest}
\end{center}
Chaque branche de l'arbre fini bien par $\bot$, nous venons donc de prouver la loi de DeMorgan, avec l'aide de notre arbre de d√©monstration. \\[1.0cm]
    Ci dessous, le lecteur pourra s'essayer √† la d√©monstrations de certaines lois logiques c√©l√®bres, avec l'aide d'un tableau ou avec un arbre. \\[1.0cm]
  \begin{equation}\neg \neg A \ffi A \end{equation}
  \begin{equation} A \land \neg A \ffi F \end{equation}
  \begin{equation} A \lor \neg A \ffi T \end{equation}
  \begin{equation} A \land F \ffi F \end{equation}
  \begin{equation} A \lor V \ffi V \end{equation}
  \begin{equation}
    \begin{cases}
      A \lor B \ffi B \lor A \\
      A \land B \ffi B \land A
    \end{cases}
  \end{equation}
  \begin{equation}
    \begin{cases}
      A \land (B \land C) \ffi (A \land B) \land C \\
      A \lor (B \lor C) \ffi (A \lor B) \lor C
    \end{cases}
  \end{equation}
  \begin{equation}A \land (B \lor C) \ffi (A \land B) \lor (A \land C) \end{equation}
  \subsection{Les ensembles de propositions.}
  Les ensembles de propositions, comme leur nom l'indique, sont des ensembles math√©matiques, compos√©s de {\bf formules logiques}.
  Ces formules sont dites soit: \\
  \begin{itemize}
  \item {\bf consistantes}, signifiant qu'il est possible d'en tirer du Vrai, par exemple $A \land B$ ou encore $\neg \neg A \imply A$.
  \item {\bf inconsistances}, signifiant que l'on ne peut en tirer que du Faux, par exemple $A \land \neg A$, ces formules peuvent √™tre not√©es $\bot$.
  \item {\bf valides}, signifiant qu'elles ne peuvent √™tre que Vraies, comme $A \lor \neg A$ (principe du tiers-exclus), une formule {\bf valide} est par d√©finition toujours {\bf consistante}, on appelle bien souvent ces formules valides des {\bf tautologies}, ces formules pourront √™tre not√©es $\top$. \\
  \item {\bf contingentes}, impliquant que l'on peut tirer de la formule du faux, tout comme du vrai, une {\bf tautologie} ne peut pas √™tre formule contingente,
  un exemple de formule contingente serait $A \lor B$.
  \end{itemize}

  Les ensembles aussi ont leur propre terminologie, ainsi, si l'on prend l'ensemble not√© $S$, il pourra √™tre qualifi√© √©galement de {\bf consistant}, si il n'y a pas de contradictions au sein de $S$ et qu'il n'y a aucune formule inconsistante contenue dans $S$, autrement $S$ sera d√©fini comme √©tant {\bf inconsistant}. \\[0.5cm]
  Il y a plusieurs mani√®res d'{\bf inf√©rer} quelque chose d'un ensemble logique. \\
  Une premi√®re mani√®re est de prendre les {\bf pr√©misses} qui nous int√©ressent, et d'√©crire \\[0.5cm]
    1. {\bf Premisse\_A} \\
    2. {\bf Premisse\_B} \\
    \hspace{0.2cm}$\vdots$ \\
    n. {\bf Premisse\_X} \\
    \hspace{0.5cm}\line(1, 0){60} \\
    $\therefore$ {\bf Conclusion} \\[0.5cm]
  Prenons un ensemble {\bf consistant} $S$ compos√© des formules $A$ et $A \imply B$. \\
  On pourrait alors noter $S$ comme √©tant $S = \{ A, A \imply B \}$ (ce qui est parfaitement √©quivalent √† √©crire $S = A \land (A \imply B)$), \\
  De ceci, nous allons utiliser l'op√©rateur de la d√©duction, $\vDash$, ceci nous permettra ainsi √©crire $S \vDash A$, litt√©ralement ``De $S$, nous d√©duisons $A$''. \\Ce principe est encore plus flagrant quand nous utilisons la notation suivante : $A, A \imply B \models A$, o√π $A, A \imply B$ n'est autre que l'ensemble S, avec une notation l√©g√®rement diff√©rente. \\[0.5cm]

  Je n'ai pas choisi cet ensemble de mani√®re anodine, car, gr√¢ce √† celui-ci, nous allons pouvoir utiliser une {\bf r√®gle d'inf√©rence} connue sous le nom du MP (Modus Ponens), le lecteur ne devrait toutefois pas s'inqui√©ter, un tableau recensant d'autres r√®gles d'inf√©rence sera pr√©sent√© √† la page suivante. \\
  Une premi√®re mani√®re de noter cette r√®gle d'inf√©rence serait de faire usage de la notation que nous avons vue plus haut. \\[0.5cm]
    1. A (De cet ensemble, nous savons A) \\
    2. $A \imply B$ (De cet ensemble, nous savons que $A \imply B$) \\
  \hspace{10cm}\line(1, 0){60} \\
  $\therefore$ B \\[0.5cm]
  Une autre mani√®re serait d'utiliser l'op√©rateur $\vDash$ (celui de la {\bf d√©duction}), de la mani√®re suivante : $A, A \implies B \vDash B$, nous pourrions m√™me √™tre tent√©s d'utiliser la {\bf r√®gle d'addition}, disant que si l'on a $S \vDash B$, alors, on peut rajouter la formule B √† S. Et ainsi, notre ensemble S de base pourra √™tre r√©√©crit en $S = {A, A \imply B, B}$
  Et maintenant, comme promis, voici un tableau comprenant toutes les r√®gles d'inf√©rence qui seront bien pratiques pour travailler avec les ensembles logiques.
  \FloatBarrier
  \begin{adjustwidth}{300pt}{0pt}
    \begin{table}[H]
    \begin{tabular}{|c|M{5.0cm}|p{5.0cm}|}
      \hline R√®gle d'inf√©rence & Tautologie & Nom de la r√®gle d'inf√©rence \\
      \hline $A, B \vDash A \land B$ & $A \land B \imply A \land B$& Loi de combinaison \\
      \hline $A, B \vDash A$ & $(A \land B) \imply A $& Loi de la simplification \\
      \hline $A, A \imply B \vDash B$ & $A \land (A \imply B) \imply B $ & Modus Ponens \\
      \hline $\neg B, A \imply B \vDash \neg A$ & $\neg B \land (A \imply B) \imply \neg A$ & Modus Tollens \\
      \hline $A \imply B, B \imply C \vDash A \imply C$ & $(A \imply B) \land (B \imply C) \imply (A \imply C)$ & Syllogisme hypoth√©tique \\
      \hline $A \lor B, \neg A \vDash A$ & $(A \lor B) \land \neg A \imply B$ & Syllogisme disjonctif \\
      \hline $A \imply B \vDash A \imply (A \land B)$ & $(A \imply B) \imply (A \imply (A \land B)$ & R√®gle d'absorption \\
      \hline $A \imply B, C \imply B, A \lor C \vDash B$ & $(A \imply B) \land (C \imply B) \land (A \lor C) \imply B$ & Elimination disjonctive\\
      \hline $A, \neg A \vDash B$ & $A \land \neg A \imply B$ & Principe d'explosion \\
      \hline
    \end{tabular}
  \end{table}
\end{adjustwidth}
\FloatBarrier
Le lecteur pourra s'exercer √† d√©montrer la validit√© des tautologies pr√©sent√©es dans le tableau-ci dessus en tant qu'exercice. \\
\subsubsection{Le besoin d'algorithme, pr√©sentation de l'algorithme de Quine.}

Un ensemble de formules, tout comme une formule peut-√™tre inconsistant, cela signifie que notre ensemble est √©quivalent √† F,et comme nous l'avons vu dans le tableau ci-dessus, on peut d√©duire absolument n'importe quoi d'un ensemble inconsistant.\\

Le probl√®me des tableaux de v√©rit√©s, c'est qu'ils prennent de la place, et m√™me, beaucoup de place. C'est pour cela qu'est venu la n√©cessit√© de cr√©er des algorithmes de r√©solution d'ensembles de formules, afin de faciliter le travail des logiciens, et ainsi, de r√©duire le temps de calcul n√©cessaire √† un ordinateur. \\

L'algorithme de Quine se d√©roule en plusieurs √©tapes, tout d'abord, nous allons simplifier, si possibles, les formules logiques contenues dans notre ensemble de formules, par exemple, au lieu d'√©crire $A \lor V$, nous pourrons √©crire simplement $ V $, et ainsi, supprimer ce $V$ de notre ensemble, comme $B, V \models B$, il y a bien d'autres simplifications possibles, nous laisserons au lecteur le soin d'en trouver.\\

Une fois cette premi√®re √©tape pass√©e, il suffit d'utiliser un arbre logique (ou √©ventuellement une table de v√©rit√©) et enfin, nous avons pu prouver des formules logiques avec l'aide de l'agorithme de Quine.
\subsection{Une logique? Des logiques!}
Les logiciens, non-contents de la seule logique propositionnelle, ont cr√©√©e un tr√®s grand nombre de logique, j'en liste quelques une ci-dessous.
\begin{itemize}
  \item La logique lin√©aire, cr√©√©e par un fran√ßais, elle est bas√©e sur la gestion de ressources, c'est une des nombreuses logiques n'excluant pas le tiers exclus, en effet, en logique lin√©aire, $A \lor \neg A \nvDash V$, cela est simplement du au fait que nous ``utilisons'' la ressource A une fois, elle n'existe donc plus r√©ellement, et donc $\neg A$ n'existe pas comme A est devenu ind√©termin√©.
  \item La logique floue, dans laquelle une proposition est vraie selon un certain degr√© de probabilit√©.
  \item La logique de premier ordre, ou logique des pr√©dicats, cette logique sera abord√©e dans le chap√Ætre sur Prolog.
  \item La logique bool√©enne, elle est bas√©e sur les portes logiques, les circuits logiques, et les ensembles.
  \item La logique combinatoire, logique invent√©e pour formaliser la notion de fonction, et pour limiter le nombre d'op√©rateurs n√©cessaires pour d√©finir le calcul des pr√©dicats.
  \item La logique modale, ayant recours √† des op√©rateurs comme ``il est n√©cessaire que'' ou ``il est possible que''.
  \item Et bien d'autres...
\end{itemize}
\vfill
\subsection{Introduction √† Prolog et √† la logique des Pr√©dicats.}
Dans cette nouvelle sous-section, nous allons nous int√©resser √† la logique des pr√©dicats, connue √©galement sous le nom de logique de premier ordre. \\
Tout d'abord, en logique des pr√©dicats, nous aurons besoin de deux nouveaux {\bf quantificateurs}. \\
Ceux-ci sont le quantificateur {\bf universel}, not√© $\forall$ [lisez ``pour tout''], et le quantificateur {\bf existentiel}, not√© $\exists$ [lisez ``il existe'']. \\
A ces deux quantificateurs viennent s'ajouter:
\begin{itemize}
  \item Des {\bf connecteurs logiques}, qui ont √©t√© discut√©s dans la section pr√©c√©dente.
  \item Des {\bf constantes}, celles-ci repr√©sentent un √©v√©nement, une personne ou un objet en particulier, nous noterons ces constantes avec une majuscule comme premi√®re lettre et un nombre √† la fin, par exemple ``Turing\_1'' ou encore ``Chaise\_2''.
  \item Des {\bf variables}, celles-ci repr√©sentent un concept g√©n√©ral ou un ensemble, par exemple, l'ensemble des math√©maticiens, ou encore l'ensemble des chaises dans le monde. Nous noterons ces variables en minuscules, par exemple ``math√©maticiens'' ou encore ``chaise''.
  \item Des {\bf pr√©dicats}, ceux-ci nous permettent d'√©tablir des liens entre nos diff√©rentes variables et constantes, nous noterons nos pr√©dicats avec une majuscule en premi√®re lettre, par exemple ``{\bf Mortel}(x)'' ou encore ``{\bf Humain}(x)''.
  \item Des {\bf fonctions}, qui ont pour but de retourner une valeur, pouvant-√™tre autre chose que vrai ou faux. Nous noterons celles-ci en toutes minuscules.
\end{itemize}
\subsubsection{Exemples.}
Pour se faire une bonne id√©e, voici quelques phrases fran√ßaises ``traduites'' en logique des pr√©dicats. \\[0.5cm]
1. Tout les math√©maticiens sont cools. \\
=$>$ $\forall$x ({\bf Math√©maticien}(x) $\imply$ {\bf Cool}(x)). \\[0.2cm]
2. Alan Turing et Alonzo Church sont des math√©maticiens. \\
=$>$ {\bf Math√©maticien}(Turing\_1) $\land$ {\bf Math√©maticien}(Church\_1). \\[0.2cm]
3. Il y a des chats qui ne sont pas noirs. \\
=$>$ $\exists$x ({\bf Chat}(x) $\land$ $\neg${\bf Noir}(x)). \\[0.2cm]

\subsubsection{Qu'est-ce que PROLOG?}
Cette petite introduction pass√©e, concentrons-nous maintenant sur le coeur du sujet: PROLOG! \\

Prolog a √©t√© invent√© en 1972 par les informaticiens fran√ßais Alain Colmerauer et Philippe Roussel. \\
C'est un langage de programmation {\bf logique} et son nom est un acronyme pour PROgrammation LOGique. \\
Prolog a √©t√© tr√®s utilis√© en Europe et au Japon dans le domaine de l'Intelligence Artificielle, tout en √©tant bas√© sur la logique propositionnelle dont nous avons pos√© les bases juste au dessus. \\
Il existe de nombreuses distributions de PROLOG\footnote{https://en.wikipedia.org/wiki/Comparison\_of\_Prolog\_implementations}, nous utiliserons ici SWI-PROLOG, avant tout pour son c√¥t√© open-source et gratuit.
\subsubsection{Introduction √† la syntaxe de Prolog}
En Prolog, contrairement aux r√®gles que nous avions √©tablies en logique des pr√©dicats, les constantes (ici appel√©s Atomes) doivent commencer par une minuscule. Les variables commencent par une majucule. A cela viennent s'ajouter les listes, d√©not√©es par des []. \\

\underline{{\bf Faits et R√®gles.}} \\[0.2cm]
En PROLOG, un fait s'√©crit simplement \\[0.2cm]

Un fait n'a pas de ``corps'', et tiendra toujours. Dans ce cas-ci, cela veut dire que Turing est un math√©maticien, quoiqu'il arrive ce {\bf fait} ne changera pas. \\

Maintenant, si nous essayons de reformuler l'exemple n¬∞1 de notre derni√®re section, ``tous les math√©maticiens sont cools'' en Prolog, cela donne ceci : \\[0.2cm]

On remarque tout de suite que cela est plut√¥t facile √† lire, de plus, si nous ouvrons notre interpr√®te Prolog, voil√† ce que nous obtenons: \\[0.2cm]

Tout cela est tr√®s bien, mais, si j'essaye de demander √† prolog si alonzo\_church est cool, que se passe-t-il? \\[0.2cm]
Pas grand chose comme nous le constatons, PROLOG pr√©f√®re √©viter de faire la moindre assomption, et r√©pondra ``Faux'' d√®s qu'il ne sait pas. \\

Ensuite, Prolog nous permet de faire de l'arithm√©tique, regardons un peu cela, avec une fonction dont le seul r√¥le est d'additionner deux nombres: \\[0.2cm]
Ouvrons maintenant l'interpr√®te et regardons la magie op√©rer: \\[0.2cm]

Mais, si pour une obscure raison, je d√©cidais de vouloir avoir B, juste en entrant A et C, comment faire? Regardons d'abord comment notre premi√®re version r√©agirait √† cela: \\[0.2cm]

Heureusement pour nous, Prolog poss√®de un module bas√© sur la logique par contraintes, pour l'utiliser, il suffit d'ajouter\footnote{https://www.swi-prolog.org/man/clpfd.html} \\[0.2cm]

au dessus de votre fichier Prolog, maintenant, modifions l√©g√®rement notre pr√©dicat \\[0.2cm]
Et voil√†! Essayons l√† maintenant avec notre interpr√®te: \\[0.2cm]

\subsubsection{Mon arbre familial, avec Prolog!}
\lstinputlisting[language=Prolog]{genealogia.prolog}
% L'exemple sera mis juste apr√®s.
\newpage
\section{L'approche algorithmique.}
\subsection{Qu'est-ce qu'un algorithme?}
\begin{center}
  \framebox{Un algorithme est une suite d'instructions permettant de r√©soudre un probl√®me.}
\end{center}

Il faut savoir que nous utilisons des algorithmes bien plus souvent que ce que l'on pourrait croire. Par exemple, quand vous pr√©parez un g√¢teau pour c√©l√©brer une quelconque occasion, vous aurez besoin d'une recette. Cette recette n'est autre que l'algorithme aidant √† la pr√©paration du g√¢teau, chaque √©tape de la recette n'√©tant qu'une instruction faisant partie de l'algorithme. \\[0.2cm]
Un des tout premiers exemples d'algorithmes est ``l'agorithme d'Euclide'', celui-ci permettait de trouver le PGCD de deux nombres. \\
Voici comment celui-ci fonctionne: \\[0.2cm]
\begin{itemize}
  \item Tout d'abord, nous prenons deux nombres a et b.
  \item Si b = 0 alors, nous retournons a comme √©tant le pgcd.
  \item Sinon, nous √©crivons que {\bf pgcd}(a, b) = {\bf pgcd}(b, a {\bf mod} b)\\[0.2cm]
\end{itemize}
Et en voici sa traduction en Common Lisp, le langage de programmation que nous utiliserons dans cette partie du dossier.
\lstinputlisting[language=Lisp]{gcd.lisp}

\subsubsection{La complexit√© des algorithmes}
Evidemment, tout les algorithmes ne se valent pas, certains sont bien plus lents que d'autres, et ce, pour une seule et m√™me t√¢che.\\
Pour juger de la {\bf complexit√©} d'un algorithme, nous utilisons la notation de Landau (dite du ``Big-O'' en anglais). \\
Cette notation a pour but d'estimer l'√©volution du nombre d'op√©rations qui seront effectu√©es par l'algorithme au cours du temps. Car au plus l'algorithme effectue d'op√©rations, au plus il sera couteux en temps, ce qui n'est pas pour nous arranger. \\[0.5cm]
Pour montrer l'importance d'avoir des algorithmes performants, nous avons impl√©ment√©s en Lisp deux algorithmes de tris diff√©rents: \\[0.2cm]
\begin{itemize}
  \item Le {\bf tri √† bulles} de complexit√© {\bf $O(n^{2})$}
  \item Le {\bf tri par fusion} de complexit√© {\bf $O(n\log{n})$}\\
\end{itemize}
Le {\bf tri √† bulles} fonctionne de la mani√®re suivante:
\begin{itemize}
  \item Prendre les deux premiers √©l√©ments de la liste.
  \item Si le premier est plus grand que le second, les √©changer, sinon, les laisser en place.
  \item Faire de m√™me jusqu'√† la fin de la liste.
  \item Une fois arriv√© √† la fin de la liste, reprendre √† partir du d√©but de la liste.
  \item Continuer ce proc√©d√© jusqu'√† ce que la liste soit parfaitement rang√©e.\\[0.2cm]
\end{itemize}
Il est impl√©ment√© de la mani√®re suivante en Common Lisp: \\[0.2cm]
\lstinputlisting[language=Lisp]{bubble_sort.lisp}
Le {\bf tri par fusion} marche de mani√®re assez diff√©rente:
\begin{itemize}
  \item Si le tableau n'a qu'un seul √©l√©ment, il est consid√©r√© comme d√©j√† tri√©.
  \item Si il a plus d'un √©l√©ment, s√©parer le tableau en deux parties √† peu pr√®s √©gales.
  \item Trier les deux parties ainsi s√©par√©es.
  \item Fusionner les deux tableaux tri√©s en un seul tableau tri√©. \\[0.2cm]
\end{itemize}
La fonction merge √©tant pr√©d√©finie en common Lisp, nous impl√©menterons notre tri par fusion ainsi.
\lstinputlisting[language=Lisp]{merge_sort.lisp}
Passons maintenant aux {\bf tests de performances}. \\
Afin de mesurer le temps pris par chacun de mes deux algorithmes, j'ai utilis√© ``time'', une macro bien pratique pour ce genre de tests. J'utilise le compilateur SBCL pour faire mes tests. En plus de cela, dans un soucis de facilit√©, j'utilise la macro random-sample, cr√©√©e par mes soins, me permettant de cr√©er une liste contenant des nombres al√©atoires, de taille fix√©e. \\
\begin{lstlisting}[language=Lisp]
;;; Ma macro random-sample bien pratique.
(defmacro random-sample (x)
   (loop for _ below ,x collect (random 1000)))
\end{lstlisting}
Sans plus attendre, voici le tableau montrant les r√©sultats de notre petite exp√©rience.
\begin{table}[H]
  \begin{tabular}{|c|c|c|}
    \hline {\bf Nombre d'√©l√©ments √† triers.} & {\bf Temps Tri √† Bulles.} & {\bf Temps Tri par fusion.} \\
    \hline 10 & 0.0000008 secondes & 0.000016 secondes \\
    100 & 0.000089 secondes & 0.000140 secondes \\
    1000 & 0.007863 secondes & 0.001188 secondes \\
    10,000 & 0.318904 secondes & 0.012558 secondes \\
    100,000 & 31.164620 secondes & 0.090092 secondes \\
    \hline
  \end{tabular}
\end{table} \smallskip
Pour des raisons pratiques, je n'ai pas pu obtenir les r√©sultats du Tri √† Bulles pour le million d'√©l√©ments. \\
Comme nous pouvons le constater sur le tableau pr√©c√©dent, la complexit√© d'un algorithme (estim√© par le Big-O) ne mesure pas le temps exact que l'algorithme prendra afin de trier une certaine liste, il s'agit simplement d'un indicateur, montrant comment √©voluera le nombre de comparaisons au cours du temps, cet indicateur devenant extr√™mement siginificatif quand n devient tr√®s grand. \\[0.5cm]
\subsection{Pr√©sentation de structures de donn√©es de base}
Pour produire une intelligence artificielle efficace, il nous faut de bons algorithmes, mais il nous faut √©galement les structures de donn√©es ad√©quates. \\
Tout d'abord, qu'est-ce qu'une structure de donn√©es?
D'apr√®s Wikipedia\footnote{https://fr.wikipedia.org/wiki/Structure\_de\_donn\%C3\%A9es}, une structure de donn√©es est une mani√®re d'organiser les donn√©es, pour les traiter plus facilement. \\
On conclut donc que le choix judicieux d'une structure de donn√©es est indispensable √† l'optimisation de la performance de notre IA.

Je pr√©sente ici trois structures de donn√©es de base.
\begin{enumerate}
  \item Les listes simplement cha√Æn√©es.
  \item Les tableaux (ou arrays en anglais.)
  \item Les tables de hachages (ou les dictionnaires.) \\[0.2cm]
\end{enumerate}

\subsubsection{Les listes simplement cha√Æn√©es.}
Une {\bf liste simplement cha√Æn√©e} est une structure de donn√©es pouvant contenir plusieurs √©l√©ments. Chaque √©l√©ment appartenant √† la liste cha√Æn√©e contient deux choses:
\begin{enumerate}
  \item La valeur de l'√©l√©ment.
  \item Un pointeur pointant vers l'√©l√©ment suivant. \\[0.2cm]
\end{enumerate}

Ainsi, nous pouvons repr√©senter une liste simplement cha√Æn√©e de la mani√®re suivante \\[0.5cm]

% TODO: INS√âRER IMAGE LISTE SIMPLEMENT CHAIN√âE.
En Lisp, une liste simplement cha√Æn√©e peut √™tre cr√©e de la mani√®re suivante. \\[0.2cm]
\begin{lstlisting}[language=Lisp]
(defparameter *my-linked-list* '(1 2 3 4 5))
\end{lstlisting}
Ainsi, si nous reprenions le dessin que nous avions utilis√© ci-dessus,
*my-linked-list* ressemblera donc √† ceci: \\[0.5cm]

% TODO: INSERER IMAGE *MY-LINKED-LIST*

D'ailleurs, pour pouvoir travailler avec des listes cha√Æn√©es, deux op√©rateurs bien pratiques s'offrent √† nous: ``car'' et ``cdr''. \\[0.2cm]
\begin{lstlisting}[language=LISP]
CL-USER> (car *my-linked-list*)
1
CL-USER> (cdr *my-linked-list*)
(2 3 4 5)
\end{lstlisting}
Nous pouvons √©galement cha√Æner nos op√©rateurs ``car'' et ``cdr'', afin de nous assurer un contr√¥le total sur notre liste simplement cha√Æn√©e.
\begin{lstlisting}[language=LISP]
CL-USER> (car (cdr *my-linked-list*))
2
CL-USER> (cadr *my-linked-list*) ; Il existe aussi une mani√®re abr√©g√©e.
2
\end{lstlisting}
Il existe √©galement la fonction ``nth'', permettant de r√©cup√©rer le n-i√®me √©l√©ment d'une liste cha√Æn√©e. (Il ne faut pas oublier que l'indexing marche comme pour les tableaux, et commence √† 0.)
\begin{lstlisting}[language=LISP]
CL-USER> (nth 2 *my-linked-list*)
3
\end{lstlisting}

\subsubsection{Les tableaux.}
Le tableau est une structure extr√™mement importante en programmation,
celle-ci nous permet de stocker un nombre fixe de donn√©es, et nous permet d'acc√©der √† ces donn√©es de mani√®re rapide. Chaque √©l√©ment du tableau se retrouve coll√© en m√©moire aux √©l√©ments qui lui sont adjacent, ainsi, pas besoin de traverser chaque √©l√©ment du tableau lorsque l'on d√©sire acc√©der au n-i√®me √©l√©ment du tableau. \\[0.2cm]
Voici comment cr√©er un tableau en Lisp:
\begin{lstlisting}[language=Lisp]
  CL-USER> (defparameter *my-array* #(1 2 3 4 5))
\end{lstlisting}
Il existe √©galement une mani√®re alternative:
\begin{lstlisting}[language=Lisp]
  CL-USER> (defparameter *my-array* (make-array 5 :initial-contents '(1 2 3 4 5)))
\end{lstlisting}
Pour r√©cup√©rer le n-i√®me √©l√©ment d'un tableau, il nous suffit de faire:
\begin{lstlisting}[language=Lisp]
  CL-USER> (aref *my-array* 2)
  3
\end{lstlisting}
\subsubsection{Tableaux vs Listes simplement cha√Æn√©es.}
Pour en conclure avec ces deux structures de donn√©es, je me propose de faire un petit tableau comparatif final, afin que le lecteur puisse mieux comprendre les diff√©rennces entre Tableau, et Liste simplement cha√Æn√©e, (que je noterai SLL pour Single-linked list).
\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline & Tableaux & SLL \\
    \hline {\bf Accession} & O(1) & O(n) \\
    \hline {\bf Insertion} & O(n) & O(1) \\
    \hline {\bf D√©l√©tion}  & O(n) & O(1) \\
    \hline
  \end{tabular}
\end{table} \smallskip
Comme on le constate sur ce tableau, les arrays ont un r√©el avantage lorsque nous d√©sirons uniquement lire un √©l√©ment de notre structure de donn√©es, toutefois, si nous d√©sirons modifier la structure de donn√©es en elle-m√™me, alors, tout devient plus probl√©matique, et cela, car notre tableau devra retrouver un autre emplacement libre pour s'y mettre en m√©moire. \\
La liste cha√Æn√©e quant √† elle, n'a pas besoin de se repositionner enti√®rement lorsqu'on lui ajoute ou qu'on lui retire un √©l√©ment, il lui suffit plut√¥t de rajouter un pointeur vers le nouvel √©l√©ment, ce qui se fait en temps constant (O(1)), peu importe la taille de la liste. Toutefois, la liste cha√Æn√©e a pour inconv√©nient d'√™tre en croissance lin√©aire lors de la recherche d'un √©l√©ment dans la liste, en effet, lors de la recherche d'un √©l√©ment dans une liste cha√Æn√©e, le programme devra d'abord passer par tout les √©l√©ments se trouvant avant celui que l'on cherche. \\
Pour d√©montrer l'importance d'utiliser la bonne structure au bon endroit, nous allons reprendre notre bon tri √† bulles. \\
Pour ceux qui en avaient oubli√© l'impl√©mentation sur les tableaux, la voici:
\lstinputlisting[language=Lisp]{bubble_sort.lisp}
Le lecteur attentif remarquera l'utilisation dans ce code de ``make-array'' et de ``aref'', tout deux synonymes de l'utilisation d'un tableau. Maintenant, transformons cette impl√©mentation en une impl√©mentation utilisant des listes simplement cha√Æn√©es. \\
Et maintenant, voici le m√™me algorithme, mais, sur les listes simplement cha√Æn√©es cette fois-ci.
\lstinputlisting[language=Lisp]{bad_bubble_sort.lisp}
Et maintenant, comparons leurs temps respectifs sur des listes de tailles diff√©rentes avec l'aide d'un nouveau tableau, (mon mode op√©ratoire reste le m√™me, j'utilise SBCL, et la macro time, pour cr√©er une liste contenant des nombres al√©atoires, j'utilise toujours ma macro random-sample.)
\begin{table}[H]
  \begin{tabular}{|c|c|c|}
    \hline & Tri √† bulles (Tableaux) & Tri √† bulles (SLL) \\
    \hline 10 &  0.0000008 secondes &  0.000009 secondes \\
    \hline 100 &  0.000089 secondes &  0.002111 secondes \\
    \hline 1000 & 0.007863 secondes &  0.750918 secondes \\
    \hline 10000 & 0.318904 secondes & 888.190640 secondes \\
    \hline 100000 &  31.164620 secondes & $>$1000 secondes \\
    \hline
  \end{tabular}
\end{table}
La diff√©rence de performance entre nos deux impl√©mentations du m√™me algorithme est √©norme, et pourtant, nous n'avons pas chang√© l'algorithme en lui-m√™me! J'esp√®re que notre petite exp√©rience montre bien au lecteur l'importance d'un choix de structure de donn√©es ad√©quat.
\subsubsection{Les tables de hachages.}
Une table de hachage (ou un dictionnaire en python) est une des structures de donn√©es les plus utiles en ce qui concerne l'optimisation d'algorithmes. \\
Son utilisation est simple; avec une table de hachage, nous relions des cl√©s avec des valeurs. \\ Ainsi, si dans une table de hachage, je relie le mot ``bonjour'' avec le mot ``hello'', mon mot ``bonjour'' sera consid√©r√© comme √©tant la cl√©, et le mot ``hello'' comme √©tant la valeur. \\
En Lisp, pour cr√©er une telle table de hachage, il faut faire: \\
\begin{lstlisting}[language=Lisp]
CL-USER> (defparameter *my-dict* (make-hash-table))
*MY-DICT*
CL-USER> (setf (gethash 'bonjour *my-dict*) 'hello)
HELLO
CL-USER> (gethash 'bonjour *my-dict*)
HELLO
\end{lstlisting}
Ce proc√©d√© √©tant toutefois un peu fastidieux, nous utiliserons ici la biblioth√®que lisp connue sous le nom de serapeum. \\
\begin{lstlisting}[language=Lisp]
CL-USER> (ql:quickload :serapeum) ;; Ici, nous d√©clarons la biblioth√®que.
To load "serapeum":
  Load 1 ASDF system:
    serapeum
; Loading "serapeum"
.
Switching to the BALLAND2006 optimizer

(:SERAPEUM)
CL-USER> (defparameter *my-dict* (serapeum:dict 'bonjour 'hello))
*MY-DICT*
CL-USER> (gethash 'bonjour *my-dict*)
HELLO
\end{lstlisting}
Pour montrer un cas pratique d'utilisation de tables de hachages, nous allons cr√©er un mini-programme qui permet de convertir des phrases en morse. \\
Ce programme se fait en deux parties, tout d'abord, nous d√©finissons une table de hachage qui nous remet la traduction morse de chaque lettre et de chaque chiffre. \\
\begin{lstlisting}[language=Lisp]
(ql:quickload :serapeum)

(defparameter *latin->morse*
  (serapeum:dict #\a "._" #\b "_..." #\c "_._." #\d "_.."
                 #\e "." #\f ".._." #\g "__." #\h "...."
                 #\i ".." #\j ".___" #\k "_._" #\l "._.."
                 #\m "__" #\n "_." #\o "___" #\p ".__."
                 #\q "__._" #\r "._." #\s "..." #\t "_"
                 #\u ".._" #\v "..._" #\w ".__" #\x "_.._"
                 #\y "_.__" #\z "__.." #\1 ".____" #\2 "..___"
                 #\3 "...__" #\4 "...._" #\5 "....." #\6 "_...."
                 #\7 "__..." #\8 "___.." #\9 "____." #\0 "_____"
                 #\SPACE " "))
\end{lstlisting}
Voici notre dictionnaire! Ne soyez pas surpris par les ``\#\'', c'est ainsi que nous d√©finissons des charact√®res en common lisp. \\
Maintenant, la deuxi√®me partie consistera simplement √† cr√©er une fonction charg√©e de transformer nos phrases vers du morse. \\
\begin{lstlisting}[language=Lisp]
(defun convert-to-morse (sentence)
  "Cette fonction s'occupe de convertir
nos phrases vers du code Morse, gr√¢ce au dictionnaire
cr√©√© ci-dessus!"
  (let ((converted-list
          (loop for letter across sentence
                collect (gethash letter *latin->morse*))))
  (format nil "~{~A~}" converted-list)))
\end{lstlisting}
Il ne nous reste plus qu'√† tester.
\begin{lstlisting}[language=Lisp]
CL-USER> (convert-to-morse "ceci est une phrase")
"_._.._._... ...._ ..__.. .__......_.._...."
\end{lstlisting}
Et voil√† comment notre programme marche! \\
Petite parenth√®se au niveau de la complexit√© de notre fonction ``convert to morse''. Tout d'abord, il faut savoir que pour chercher une valeur avec une cl√© dans un dictionnaire, la complexit√© temporelle est de O(1)! Peu importe la taille du dictionnaire, cela prendra toujours aussi peu de temps de chercher une clef dedans, c'est la raison pour laquelle ceux-ci sont tr√®s utilis√© de nos jours.
Pour les lecteurs int√©ress√©s, nous conseillons fortement de vous renseigner sur la fonction SHA, c'est gr√¢ce √† cette fonction de hachage que les dictionnaires marchent aussi bien. \\
Ainsi, pour en revenir √† notre programme, nous appliquons une op√©ration de complexit√© O(1) sur chaque √©l√©ment de notre liste, soit, n fois. On peut donc en d√©duire que notre fonction ``convert-to-morse'' est donc de complexit√© O(n), car nous appliquons n fois une op√©ration de complexit√© O(1). \\[0.2cm]
\subsubsection{Promenons-nous dans les bois.}
Pour comprendre l'int√©r√™t des arbres dichotomiques en programmation, int√©ressons nous √† un petit probl√®me assez simple. \\
Imaginez que je pense √† un nombre, compris entre 1 et 1000, et que vous deviez deviner ce nombre avec le moins d'essais possibles, √† la m√™me mani√®re que dans le jeu du ``Juste Prix'', je vous dirai si votre essai est trop grand, ou trop petit. \\
La premi√®re strat√©gie √©vidente, serait de commencer par 1, puis ensuite, si mon nombre n'est pas 1, essayer avec 2, puis ensuite, essayer avec 3, et ceci, jusqu'√† ce que vous trouviez le nombre auquel je pense. \\
Cette premi√®re strat√©gie pourrait faire penser √† la mani√®re √† laquelle il faut chercher un √©l√©ment dans une liste simplement cha√Æn√©e, en effet, si je pense au nombre 629, il va falloir passer par les 628-i√®mes √©l√©ments se trouvant avant. Dans ce cas-ci, comme pour lire un √©l√©ment dans une liste simplement cha√Æn√©e, nous dirons que la complexit√© de cet algorithme sera de O(n). \\
Une deuxi√®me mani√®re de faire serait de faire ce que l'on appelle une recherche dite ``par dichotomie''. Tout d'abord, prenons un nombre au milieu entre 1 et 1000, ici, ce sera 500, si je dis ``au dessus'', alors, il suffira de prendre le milieu entre 500 et 1000, ici, ce sera 750, d√©sormais, si je dis ``en dessous'', il faudra alors faire $\frac{500 + 750}{2} = 625$, ainsi, en appliquant cet algorithme jusqu'au bout, vous trouverez le nombre auquel je pense en utilisant un algorithme de complexit√© O(log n)! \\ Ainsi, vous trouverez gr√¢ce √† cette technique le nombre auquel je pense en maximum $\log_{2}{n}$ essais (o√π n est le nombre maximum, qui est ici 1000). \\
J'esp√®re que cette petite explication aura pu expliquer au lecteur le fonctionnement d'une recherche par dichotomie. Maintenant, pour ce qui est de l'impl√©mentation d'une telle recherche en Lisp: \\
\lstinputlisting[language=Lisp]{dichotomia.lisp}
Plus qu'√† la tester!
\begin{lstlisting}[language=Lisp]
[1] CL-USER> (binary-search 1 1000)
500?
plus-haut
750?
plus-bas
625?
plus-haut
687?
plus-bas
656?
plus-bas
640?
plus-bas
632?
plus-bas
628?
plus-haut
630?
plus-bas
629?
oui
Ton nombre a √©t√© trouv√© en 9 essais
\end{lstlisting}

Cette petite introduction √† la recherche par dichtomie servait surtout √† donner une intuition au lecteur de l'importance des arbres binaires. \\
Ceux-ci fonctionnent d'une mani√®re similaire √† notre recherche dichotomique. \\
Sur un arbre binaire, chaque noeud est soit reli√© √† rien (ou ``nil''), soit reli√© √† sa ``gauche'' √† un noeud contenant une valeur plus petite que celle de son noeud parent, soit reli√© √† sa ``droite'' √† un noeud contenant une valeur plus grande que celle de son noeud parent. Nous pouvons donc repr√©senter un arbre binaire ainsi: \\[0.2cm]

\subsection{Qu'est-ce que Lisp?}
Lisp est une famille de langages de programmation fonctionnels, invent√©s en 1958 par John McCarthy (l'homme ayant invent√© le terme ``intelligence artificielle''). \\
Ceux-ci sont reconnaissables facilement gr√¢ce au tr√®s grand nombre de parenth√®ses pr√©sentes dans chacun des dialectes de Lisp. \\
Aujourd'hui, le dialecte Lisp le plus utilis√© reste {\bf Clojure}, toutefois, il en reste d'autres gardant toujours leur cote de popularit√©, pour n'en citer que quelques-un, nous avons
\begin{itemize}
  \item {\bf Scheme}, qui est un dialecte tr√®s minimaliste de Lisp, tr√®s utilis√© au niveau acad√©mique.
  \item {\bf Emacs Lisp}, un dialecte tr√®s pratique pour tout ceux d√©sirant configurer l'√©diteur de texte Emacs.
  \item {\bf Racket}, un super-set de Scheme.
  \item {\bf Common Lisp} est le dialecte que nous utiliserons ici, ce dialecte a toujours eu la r√©putation d'√™tre plus orient√© vers les applications pratiques, et n'a jamais re√ßu de grandes faveurs acad√©miques. Common Lisp a toutefois le m√©rite d'avoir √©t√© standardis√©, de b√©n√©ficier d'un syst√®me orient√©-objet connu sous le nom de CLOS.
\end{itemize}
\subsubsection{Les bases de Lisp.}
Tout d'abord, pour commencer notre aventure avec Lisp, ouvrons donc notre REPL (cela peut-√™tre SBCL, Clisp, ou encore CCL), et additionnons deux nombres. \\
\begin{lstlisting}[language=Lisp]
CL-USER> (+ 3 5)
8
\end{lstlisting}
Cela peut sembler bien √©trange pour le non-init√©, et pourtant, tout cela est parfaitement logique. \\
En fait, lorsque l'on d√©sire appeler une fonction (comme par exemple ici ``+''), la syntaxe sera toujours ``({\bf fonction} {\bf arguments})''. Prenons quelques autres exemples avec quelques op√©rations arithm√©tiques. \\
\begin{lstlisting}[language=Lisp]
CL-USER> (- 2 1)
1
CL-USER> (* 3 4 2)
24
CL-USER> (/ 5 6)
5/6
CL-USER> (/ 5 6.0)
0.8333333
\end{lstlisting}
Comme on peut le voir, la logique reste la m√™me pour tout les op√©rateurs, aussi, cette syntaxe nous permet √©galement de mettre √† ces op√©rateurs autant d'arguments que l'on le souhaite, (l'exemple est donn√© ci-dessus avec l'op√©rateur de multiplication.). \\
Egalement, l'op√©ration de division ne remet pas directement un nombre √† virgule, mais plut√¥t un Ratio, si l'on ne lui donne pour argument uniquement des nombres entiers. \\
Pour d√©clarer une variable en Lisp, plusieurs choix s'offrent √† nous, je pr√©senterai uniquement ici ``defparameter''.
\begin{lstlisting}[language=Lisp]
CL-USER> (defparameter *test* 'bonjour)
*TEST*
CL-USER> *test*
BONJOUR
\end{lstlisting}
J'en profite pour attirer l'attention sur l'utilisation de ``*'' autour du nom de la variable. Ceux-ci sont appel√©s les ``cache-oreilles'', il ne s'agit ici que d'une convention, il est tout √† fait acceptable de ne pas utiliser de caches-oreilles lors ed la d√©finition d'une variable globale. \\[0.2cm]
Maintenant, j'utiliserai la fin de cette petite introduction comme pr√©texte pour pr√©senter ``la r√©cursion''. \\
Pour montrer un exemple de fonction r√©cursive, je pr√©senterai ici la fonction factorielle, fonction r√©cursive par excellence. \\
Tout d'abord, pour d√©clarer une fonction, nous utiliserons le mot-cl√© {\bf defun}.
\begin{lstlisting}[language=Lisp]
CL-USER> (defun factorial (x) ...)
\end{lstlisting}
Il faut ensuite r√©fl√©chir √† ce qu'il faudra mettre au sein de notre fonction. \\
La r√©cursion est un processus en 3 √©tapes. \\
\begin{enumerate}
  \item Trouver la valeur de f(0) (ou de n'importe quel cas de base.)
  \item Supposer que cette fonction remettra un nombre correct pour f(n-1).
  \item Trouver la valeur de f(n) en fonction de f(n-1).
\end{enumerate}
L'exemple ici est assez simple, et est souvent donn√© en introduction √† la r√©cursion. Voici donc une d√©finition formelle de notre fonction factorielle. \\
$$\begin{cases}0! = 1 \\ n! = n \cdot (n - 1)! \end{cases}$$
Ainsi, uniquement gr√¢ce √† cette simple d√©finition, nous allons pouvoir coder cette fonction en Common Lisp \\
\begin{lstlisting}[language=Lisp]
CL-USER> (defun factorial (x)
                   (if (= x 0)
                       1
                      (* x (factorial (- x 1)))))
FACTORIAL
\end{lstlisting}
On constate directement la simplicit√© et l'√©l√©gance avec laquelle cette fonction peut-√™tre ainsi programm√©e. D'autres fonctions peuvent-√™tre cod√©e de mani√®re r√©cursive, l'exemple de l'algorithme de tri par fusion, ou encore l'agorithme d'Euclide pour calculer le pgcd sont deux exemples de fonctions r√©cursives dont j'ai pu montrer l'impl√©mentation ci-dessus. \\
Un autre exemple d'algorithme utilisant la r√©cursion serait l'algorithme ``quick-sort'' dit du ``tri-rapide'', en voici son impl√©mentation \\
\lstinputlisting[language=Lisp]{quick_sort.lisp}

Si le lecteur en sent l'envie, nous l'encourageons √† essayer de coder la fonction r√©cursive d'Ackermann, ou encore la McCarthy 91. \\
\subsubsection{Programme Lisp pour r√©soudre parfaitement le jeu de Nim.}
Afin que le lecteur se fasse une id√©e de comment utiliser dans des cas plus concrets, nous allons vous pr√©senter une intelligence artificielle, assez basique, gagnant au jeu de Nim √† plusieurs tas. (Aussi connu sous le nom de jeu de Marienbad.), dans ce jeu, plusieurs alumettes sont dispos√©es sur plusieurs piles, le but du jeu est de r√©colter la derni√®re alumette. \\
L'intelligence gagnant √† ce genre de jeux est assez basique, en effet, le jeu de Nim √† plusieurs tas est un jeu r√©solu parfaitement. \\
La strat√©gie gagnante pour ce jeu est simple, nous d√©finissons une position gagnante une position o√π la``nim-somme'' (qui est en r√©alit√© l'op√©rateur ``xor'' ou $\oplus$ appliqu√© √† la repr√©sentation binaire de notre tas) est diff√©rent de 0, et √† l'inverse, une position perdante est une position o√π la ``nim-somme'' appliqu√©e aux tas est √©gale √† 0. \\
Un exemple de position perdante serait la position o√π les alumettes seraient r√©parties sur 4 tas avec 1 alumette sur le premier tas, 3 sur le deuxi√®me, 5 sur le 3i√®me, et 7 sur le dernier. \\
$$1 \oplus 3 \oplus 5 \oplus 7 = 0$$
Pour se le prouver, on peut utiliser notre interpr√®te Lisp et faire
\begin{lstlisting}[language=Lisp]
CL-USER> (logxor 1 3 5 7)
0
\end{lstlisting}
Le but de l'ordinateur sera donc de toujours se trouver en position de s√©curit√©, et de toujours mettre le joueur en position perdante. \\
Le twist que nous avons apport√© est le fait que le joueur peut d√©cider des tas avec lesquels ils va jouer, et ainsi, mettre directement l'ordinateur en position de d√©faite, notre IA devra donc se montrer capable de jouer des coups, m√™me en perdant. \\
\lstinputlisting[language=Lisp, linerange={1-2}]{Nim/nim-game-player.lisp}
Ici, je ne fais que d√©finir une variable globale *heaps*, celle-ci repr√©sentera les tas disponibles au travers de mon programme. \\
\lstinputlisting[language=Lisp, linerange={4-10, 27-32, 61-67}]{Nim/nim-game-player.lisp}
Ces deuc fonctions seront dites des ``fonction d'aide'', elles auront surtout pour utilit√© de ne pas devoir surcharger les fonctions principales. \\
Le lecteur attentif remarquera que je termine le nom de ces fonctions par un ``p'', cela est d√ª au fait que ces fonctions sont des {\bf pr√©dicats}, elles ne peuvent retourner que ``t'' ou ``nil'' (``vrai'' ou ``faux''), ceci n'√©tant √©galement qu'une convention, si le lecteur d√©sire √©crire des pr√©dicats sans laisser de ``p'' au bout, SBCL ne lui trouvera rien √† redire.\\
Aussi, on peut remarquer dans les deux premi√®res fonctions l'utilisation de ``reduce'', il s'agit d'une fonction destin√©e aux {\bf catamorphismes}, cela veut dire qu'elles permettent de passer d'une structure de donn√©es comme une liste, ou un arbre, vers un scalaire, comme un entier ou encore un flottant. \\
Egalement, j'utilise \#', ce symbole nous permet d'expliciter que nous utilisons une fonction, et pas une variable.\\
\lstinputlisting[language=Lisp, linerange={12-26, 34-48}]{Nim/nim-game-player.lisp}
Nous voici enfin au c≈ìur du programme. Avec nos fonctions ``play-winning-move'' et ``play-random-legal-move'' sont nos deux fonctions o√π est contenue notre joueur, les commentaires explicitant d√©j√† leurs actions, je me concentrerai surtout sur l'impl√©mentation. \\ Comme nous le remarquons, j'utilise {\bf let} et {\bf loop}, {\bf let} me permet de d√©clarer des variables dites ``locales'', cela me permet d'avoir un code propre, o√π chaque chose reste √† sa place. \\ {\bf loop} est une macro, qui permet d'it√©rer, ou de r√©p√©ter un nombre certain de fois une m√™me action, je l'utilise ici en raison de la lisibilit√© de celle-ci, certains pr√©f√®rent la macro ``do'', je trouve cette derni√®re illisible, mais j'encourage le lecteur  se renseigner sur cette derni√®re si le coeur le lui en dit.\\
\lstinputlisting[language=Lisp, linerange={50-60}]{Nim/nim-game-player.lisp}
Je ne ferai remarquer ici que l'utilisation de la macro {\bf cond}, une autre mani√®re d'√©crire des conditions en Lisp.
\lstinputlisting[language=Lisp, linerange={69-95}]{Nim/nim-game-player.lisp}
Cette tr√®s longue fonction fait office d'interface utilisateur. Nous avons d√©j√† fait remarqu√© au lecteur en commentaires l'utilisation de la r√©cursion. \\
Egalement, nous signalons {\bf progn}, une fonction bien pratique pour d√©finir des blocs de code.
\lstinputlisting[language=Lisp, linerange={98-108}]{Nim/nim-game-player.lisp}
Nous finissons enfin notre programme avec cette fonction nim-game-repl, permettant de commencer une partie entre humain et ordinateur.
\subsection{Le pathfinding.}
\subsubsection{Pr√©sentation du probl√®me.}
\subsubsection{L'algorithme de Dijkstra.}
\subsubsection{Le besoin d'heuristiques.}
\subsubsection{Dijkstra avec de l'heuristique: A*!}
\lstinputlisting[language=Lisp]{PathFinders/dijkstra-path.lisp}
\subsection{Des programmes et des jeux!}
\subsubsection{L'agorithme Minimax.}
\subsubsection{$\alpha\beta$-√©lagage.}
\subsubsection{Du dynamisme bon sang!}
\subsection{Un programme de jeu.}
\newpage
\section{Le Machine Learning.}
\subsection{D√©finition du Machine Learning}
Le Machine Learning, ou Apprentissage Automatique, est un type d'intelligence artificielle qui avec les donn√©es √† analyser et sur lesquelles s'entra√Æner permet aux ordinateurs d‚Äôapprendre par exp√©rience sans avoir √©t√© explicitement programm√© √† cet effet ou par intervention humaine. Cela consiste en algorithmes d‚Äôapprentissage qui am√©liorent leur performance √† ex√©cuter des t√¢ches au fil du temps gr√¢ce √† de l‚Äôexp√©rience.\\[1.0cm]
\subsection{Les Maths dans le Machine Leanring.}
\begin{enumerate}
  \item De nombreux data scientists (charg√©s de la gestion, de l‚Äôanalyse et de l‚Äôexploitation des donn√©es au sein d‚Äôune entreprise) consid√®rent le machine Learning comme un apprentissage statistique.
  \item Matrice et alg√®bre matricielle, exemple :
        \begin{enumerate}
          \item Les suggestions d‚Äôamis sur Facebook
          \item Recommandation de vid√©o sur Facebook
          \item $\cdots$
        \end{enumerate}
  \item Fonction, variable, √©quation et graphique, ...
\end{enumerate}

\subsection{Les r√©saux de neurones}
Une couche de neurones d‚Äôentr√©es, plusieurs couches cach√©es, une couche de sortie suivie d‚Äôune fonction d‚Äôactivation.
Chaque neurone poss√®de une valeur obtenue par une fonction de combinaison √©tant la somme des valeurs des neurones de la couche pr√©c√©dente, chacune multipli√©e par un poids sp√©cifique
$ z = x_1 \cdot p_1 + x_2 \cdot p_2 + \cdots + x_n \cdot p_n $ \\
Une fois la (ou les) valeur de la couche de sortie obtenue, on applique √† celle-ci une fonction d‚Äôactivation qui transforme la valeur en fonction d‚Äôun seuil. Si en dessous du seuil, inactif (0/-1), aux environs du seuil, phase de transition, et au-dessus du seuil, actif (1/$>$1). Le type de fonction varie d‚Äôun cas √† l‚Äôautre, mais les plus r√©currentes sont la fonction sigmo√Øde $ \frac{1}{1 + e^{-x}}$ la fonction tangente hyperbolique $ \frac{2} {1 + e^{-2x}} -1 $
ou encore la fonction ReLU $\begin{cases} 0 & x < 0 \\ x & x >= 0 \end{cases}$ \\
Durant l‚Äôapprentissage, les poids sont des valeurs prises au hasard. Il faut donc les ajuster pour fournir une r√©ponse qui se rapproche au mieux de la r√©alit√©. Comme on entra√Æne notre r√©seau, on conna√Æt la vraie valeur finale. On va donc appliquer une fonction de co√ªt afin de calculer le gradient d‚Äôerreur entre la valeur r√©elle et la valeur pr√©dite $ \frac{1}{2}(y_r - y_p)^2 $, et ainsi mettre √† jour les poids par r√©tropropagation (! il y a des maths plus compliqu√©es derri√®re). A chaque nouvelles donn√©es inject√©es lors de l‚Äôapprentissage, le r√©seau est plus performant.

\subsection{Intro au langage Python}
\begin{enumerate}
  \item Cr√©√© par Guido van Rossum au Stichting Mathematisch Centrum en Hollande.
  \item Python est le successeur d‚Äôun langage de programmation nomm√© ‚ÄúABC‚Äù
  \item Le nom du langage vient de la s√©rie Monty Python‚Äôs flying Circus dont Guido Van Rossum √©tait fan. Cependant l‚Äôimage du serpent paraissait plus √©vidente pour tout le monde, il a donc d√©cid√© d‚Äôutiliser celle-ci comme symbole du langage.
  \item La premi√®re version de Python paraissait en 1991
  \item C‚Äôest un langage de programmation open source, c‚Äôest √† dire gratuit et libre d‚Äôutilisation
  \item Python au fil des ann√©es a √©t√© mis √† jour beaucoup de fois et est pass√© d‚Äôune version 1.5 en 1999 jusqu‚Äô√† 3.9 cette ann√©e (2020), nous nous int√©resserons surtout aux diff√©rences entre python 2 et python 3 qui ont √©t√© les plus marquantes.
      \begin{enumerate}
          \item \underline{{\bf Python2: }}
              \begin{itemize}
                \item version plus facile que python 1 mais contenant plus d‚Äôerreurs.
                      \begin{enumerate}
                        \item erreur de syntaxe, manque de ‚Äò:‚Äô, manque d‚Äôune lettre, etc (erreur d‚Äôanalyse de code)
                        \item Nouvelles exceptions, comme ZeroDivisionError(division par z√©ro), ValueError(valeur incorrecte), Etc.
                      \end{enumerate}
                \item  Pas difficile √† reconvertir vers python 3 mais ce n‚Äôest pas fiable
                \item La programmation est plus complexe sur python 2
                \item Le support de la version 2 de python a √©t√© abandonn√© cette ann√©e, en 2020.
                \item etc (opposition des tirets de python 3)
              \end{itemize}
        \item \underline{{\bf Python3:}}
              \begin{itemize}
                \item syntaxe plus simple et facilement compr√©hensible.
                \item  stockage unicode (√©change de texte dans diff√©rentes langues).
                \item La valeur des variables utilis√©es ne change jamais.
                \item Certaines fonctions on √©t√© remplac√© par d‚Äôautres (python3; range(), python2; xrange()) range ou xrange servent toutes les 2 a cr√©er une liste et aussi des it√©rations (r√©p√©titions).
                \item Cr√©ation de biblioth√®ques qui ne peuvent pas √™tre cr√©√©es avec python2.
                      \begin{itemize}
                        \item Python3 est aujourd‚Äôhui la version la plus conseill√©e surtout pour ceux d√©sirant de commencer la programmation
                      \end{itemize}
              \end{itemize}
      \end{enumerate}
\end{enumerate}

\end{document}
