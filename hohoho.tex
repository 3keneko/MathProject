% Yay, the article for the end of this year, in LaTeX.

\documentclass[a4paper, 12pt]{article}

\newcommand{\ffi}{\Leftrightarrow}
\newcommand{\imply}{\Rightarrow}


\usepackage[french]{babel}
\usepackage{listings}
\usepackage{fancyhdr, fancybox}
\usepackage{amsmath, amssymb}
\usepackage{xcolor, changepage, array, placeins, float, verbatim}
\usepackage{qtree, forest}
\usepackage[utf8]{inputenc}
\usepackage{listingsutf8}
\pagestyle{fancy}

\definecolor{codecomments}{HTML}{FFA700}
\definecolor{codenumbers}{HTML}{D62D20}
\definecolor{codestrings}{HTML}{008744}
% \definecolor{backcolour}{HTML}{F7F7F7}
\definecolor{keycolor}{HTML}{3B5998}%{0057E7}
\definecolor{backcolour}{HTML}{FFFFFF}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codecomments},
    keywordstyle=\color{keycolor},
    numberstyle=\tiny\color{codenumbers},
    stringstyle=\color{codestrings},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbersep=5pt,
    showspaces=false,
    xleftmargin=\parindent,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    rulecolor=\color{black},
    frame=L
  }

\lstset{
    style=mystyle,
    morecomment=[s][\color{codenumbers}]{@}{\ },
    extendedchars=true,
    literate={é}{{\'e}}1
    {â}{{\^a}}1
    {à}{{\`a}}1
    {ê}{{\^e}}1
    {è}{{\`e}}1
    {î}{{\^i}}1
    {0}{{{\color{codenumbers}0}}}1
    {1}{{{\color{codenumbers}1}}}1
    {2}{{{\color{codenumbers}2}}}1
    {3}{{{\color{codenumbers}3}}}1
    {4}{{{\color{codenumbers}4}}}1
    {5}{{{\color{codenumbers}5}}}1
    {6}{{{\color{codenumbers}6}}}1
    {7}{{{\color{codenumbers}7}}}1
    {8}{{{\color{codenumbers}8}}}1
    {9}{{{\color{codenumbers}9}}}1
    {1-}{{{\color{codenumbers}1-}}}2
    {1+}{{{\color{codenumbers}1+}}}2
    {remove-if}{{{\color{keycolor}remove-if}}}8
    {if}{{{\color{keycolor}if}}}2
    {True}{{{\color{teal}True}}}4
    {False}{{{\color{teal}False}}}4
    {await}{{{\color{keycolor}await}}}5
    {\ as\ }{{{\color{keycolor}as}}}4
    {async\ }{{{\color{keycolor}async}}}5
  }
\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\sectionmark}[ 1 ]{\markboth{\thesection. #1 }{ }}
\renewcommand{\subsectionmark}[ 1 ]{\markright{\thesubsection. #1 }}

\renewcommand{\labelenumi}{\alph{enumi}.}
\renewcommand{\theenumi}{\alph{enumi}.}
\renewcommand{\labelenumii}{\roman{enumii}.}
\renewcommand{\theenumii}{\roman{enumii}.}

\rhead[\textbf{}]{\textbf{}}
\lhead[\textbf{}]{\textbf{}}
\lfoot[{\bf \thepage}]{{\bf \thepage}}
\rfoot[{\bf \thepage}]{\textbf{IA PAS DE SOUCIS!}}
\cfoot[]{}

\numberwithin{equation}{subsection}
\renewcommand{\headrulewidth}{ 0.15 mm}
\renewcommand{\footrulewidth}{ 0.15 mm}
\addtolength{\headwidth}{\marginparsep}
\addtolength{\headwidth}{\marginparwidth}

\newcolumntype{M}[ 1 ]{>{\centering\arraybackslash}m{#1}}
\title{IA Pas de Soucis!}
\author{Un projet de Evrard Maurice,\\ Lejeune Grégory,\\ Lejeune Lucas,\\ Mathieu Louca,\\ Pluvinage Victor\\ et de Ralet Vincent.}

\begin{document}
\maketitle
\newpage

\section{Histoire.}

\subsection{C A VOUS.}

\newpage

\section{L'approche logique.}
\newpage
\subsection{Les bases de la logique}
  \subsubsection{Introduction à la logique propositionnelle.}
     L'importance de la logique propositionnelle est immense en mathématiques et en cryptographie, mais également, comme nous allons le voir, en informatique.\\
     Voici une fameuse lapalissade, exemple typique d'utilisation d'une phrase ne découlant de rien d'autre que de cette logique:
  \begin{center}
    \shadowbox{{\bf ''15 minutes avant sa mort, il était encore en vie.''}\footnotemark} \footnotetext{ https://fr.wikipedia.org/wiki/Lapalissade}
  \end{center}
     Évidemment, grâce à notre capacité déductionnelle, nous pouvons tous définir cette phrase comme vraie, c'est ici, une vérité dite ``de  langage''. \\[0.5cm]

  \subsubsection{Un peu de vocabulaire!}
     La logique propositionnelle possède son propre vocabulaire, il est presque indispensable de connaître son vocabulaire et sa syntaxe afin même de  pouvoir en comprendre les concepts.\\
     Tout d'abord, un {\bf langage formel} est un ensemble de mots que l'on peut obtenir en utilisant un alphabet\footnote{Cela peut être un alphabet comme abcd...yz tout comme un alphabet composé uniquement de 1 et de 0.}, un langage possède plusieurs {\bf lois}, cet ensemble de lois sera appelé la {\bf syntaxe}, qui définissent les différentes manières grâce auxquelles les éléments de l'alphabet (aussi appelés  les {\bf symboles}) peuvent se placer pour former quelque chose de cohérent au langage.\\ Par exemple, en français, vous n'écririez pas ``Jème lai vwaturres'', mais plutôt, ``j'aime les voitures'', aussi bête que ce petit exemple puisse paraître, il s'agit  là de l'une des nombreuses fois où l'on se plie aux règles d'une grammaire logique. \\
     Un mot respectant toutes les règles de syntaxe sera alors appelé un {\bf mot bien-formé}. \\
     {\bf La logique propositionnelle} se compose donc d'un langage formel, et de sémantiques donnant du sens aux mots bien formés, répondant au nom de {\bf propositions}. \\
     Les propositions logiques sont désignées par des lettres, comme $ A, B, C$..., ou par des lettres indicées comme $ A_2, B_{4}$...
     Pour relier ces propositions, on utilise des connecteurs, répertoriés dans le tableau ci-dessous. \\
     \begin{table}[!t]
       \centering
       \begin{tabular}{|c|c|c|}
         %!{\vrule width 0.8mm}>{\bfseries}l|
         %>{$}<{$}!{\vrule width 0.8mm}}
         \hline {\bf nom }       & {\bf symbole}     & {\bf autre nom}  \\
         \hline négation         & $\neg$            & NOT              \\
         conjonction             & $\land$           & AND              \\
         disjonction (I)         & $\lor$            & OR               \\
         disjonction (E)         & $\oplus$          & XOR              \\
         implication             & $\imply$          & IF..THEN         \\
         équivalence             & $\ffi$            & IFF              \\
         \hline
       \end{tabular}
    \end{table}
  En plus de ces connecteurs viennent s'ajouter les deux valeurs logiques à la base de tout, Vrai et Faux.
    \subsubsection{Pour quelques exemples de plus...}
        Voici quelques exemples d'énoncés de logique propositionnelle dans un cadre assez éloigné des mathématiques, en espérant que cela fasse sens au lecteur.\\
        Supposons que $A$ et $B$ soient deux propositions logiques. \\
        $A$: Je suis boulanger. \\
        $B$: Je sais faire des gâteaux. \\
        Nous pouvons ainsi relier ces deux propositions avec les connecteurs vus dans le tableau ci-dessus. \\
        $\neg A$: Je ne suis pas boulanger. \\
        $\neg B$: Je ne sais pas faire des gâteaux. \\
        $A \land B$: Je suis boulanger et je sais faire des gâteaux. \\
        $A \lor B$: Je suis boulanger ou je sais faire des gâteaux (Les deux propositions peuvent être vraies, tout comme une seule des deux). \\
        $A \oplus B$: Je suis boulanger ou alors je sais faire des gâteaux. (Une seule de ces deux propositions doit être vraie) \\
        $A \imply B$: Je suis boulanger, donc je sais faire des gâteaux. \\
        $A \ffi B$: Je suis boulanger si et seulement si je sais faire des gâteaux. \\
        ... \\
    \subsubsection{Quelques tables de vérité.}
    Après tant d'exemples ``instructifs'', il serait temps de passer aux fameuses {\bf tables de vérité}, ces tables seront d'une importance capitale lors de résolutions de problèmes, les voici donc: \\[15.0cm]
    \begin{table}[!t]
      \hspace{1.0cm}
      \begin{minipage}[c]{0.1\linewidth}
        \centering
        \caption{Négation.}
        \label{neg_table}
      \begin{tabular}{|c|c|}
        \hline $A$ & $\neg A$ \\
        \hline  F  &     V    \\
                V  &     F    \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{2.0cm}
    \begin{minipage}[c]{0.22\linewidth}
      \centering
      \caption{\\Conjonction.}
      \label{and_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \land B$ \\
        \hline  F  &  F  &      F      \\
                F  &  V  &      F      \\
                V  &  F  &      F      \\
                V  &  V  &      V      \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.27\linewidth}
      \centering
      \caption{\\Disjonction (OR).}
      \label{or_table}
    \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \lor B$  \\
        \hline  F  &  F  &      F      \\
                F  &  V  &      V      \\
                V  &  F  &      V      \\
                V  &  V  &      V      \\
        \hline
    \end{tabular}
  \end{minipage}
  \\[1.0cm]
  \begin{minipage}[c]{0.27\linewidth}
    \centering
    \caption{\\Disjonction (XOR).}
    \label{xor_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \oplus B$ \\
        \hline  F  &  F  &       F      \\
                F  &  V  &       V      \\
                V  &  F  &       V      \\
                V  &  V  &       F      \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.22\linewidth}
      \centering
      \caption{\\Implication.}
      \label{imply_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \imply B$ \\
        \hline  F  &  F  &       V        \\
                F  &  V  &       V        \\
                V  &  F  &       F        \\
                V  &  V  &       V        \\
        \hline
      \end{tabular}
    \end{minipage}
    \hspace{1.0cm}
    \begin{minipage}[c]{0.1\linewidth}
      \centering
      \caption{Équivalence}
      \label{iff_table}
      \begin{tabular}{|c|c|c|}
        \hline $A$ & $B$ & $A \ffi B$ \\
        \hline  F  &  F  &      V     \\
                F  &  V  &      F     \\
                V  &  F  &      F     \\
                V  &  V  &      V     \\
        \hline
      \end{tabular}
    \end{minipage}
  \end{table}
  Les tables 1 à 4 doivent sans doute paraître logique, je m'attarderai toutefois sur la table 5, en effet les deux phrases $F \imply V$ et $F \imply F$ sont toutes deux vraies.
  Cela est du au {\bf principe d'explosion}\footnote{https://fr.wikipedia.org/wiki/Principe\_d$\%$27explosion}: Du faux, on peut déduire absolument n'importe quoi! (On verra plus tard que l'on peut noter ceci $A \land \neg A \models B$).\\
  Pour ce qui est de la table 6, il faut savoir que certains notent $\ffi$ comme étant $\equiv$, cette notation a l'avantage d'accentuer le fait que cette relation n'est autre que la relation d'équivalence.
  \subsubsection{Résolution de problèmes en logique propositionnelle.}
  Maintenant que nous avons acquis les bases de la logique propositionnelle,  attaquons nous à quelques problèmes.\\
  En voici un premier,
  \begin{center}
    \Ovalbox{$ \neg (A \land B ) \ffi \neg A \lor \neg B$}
  \end{center}
  Pour résoudre ceci, nous allons utiliser une grande table de vérité: \newpage
  \begin{table}[!t]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
      \hline $A$ & $B$ & $A \land B$ & $\neg (A \land B)$ & $\neg A$ & $\neg B$ & $\neg A \lor \neg B$ & $\neg (A \land B) \ffi \neg A \lor \neg B$ \\
      \hline  F  &  F  &      F      &          V         &     V    &     V    &          V           &                     V                      \\
              F  &  V  &      F      &          V         &     V    &     F    &          V           &                     V                      \\
              V  &  F  &      F      &          V         &     F    &     V    &          V           &                     V                      \\
              V  &  V  &      V      &          F         &     F    &     F    &          F           &                     V                      \\
      \hline
    \end{tabular}
  \end{table}
  Ainsi, comme nous pouvons le constater, la dernière ligne est remplie de ``V'', cela veut donc dire que nous venons de prouver la relation $\neg (A \land B) \ffi \neg A \lor \neg B$ , aussi connue sous le nom de ``la loi de DeMorgan'', nous avons prouvé par la même occasion que $\neg (A \land B) \ffi \neg A \lor B$ est {\bf valide}, cela veut dire qu'elle sera toujours vraie, peu-importe les A, et les B.\\[0.5cm]
  Il existe toutefois une autre manière de faire, il s'agit d'utiliser un arbre, cette méthode requiert moins d'étapes et nous permettra de résoudre certains problèmes de manière plus simple. Toutefois, il y a quelques règles à respecter lors de l'utilisation d'un arbre, ces  règles sont répertoriées dans le tableau ci-dessous. \\
  \begin{center}
    \begin{table}[!hbt]
      \centering
    \begin{tabular}{|M{2.5cm}|M{2.5cm}|M{2.5cm}|}
      \hline \begin{forest} [$\neg (\neg \phi)$ [$\phi$]]\end{forest} & \begin{forest} [$\phi \land \psi$ [$\phi$ [$\psi$]]] \end{forest} & \begin{forest} [$\neg (\psi \land \phi)$ [$\neg \psi$] [$\neg \phi$]] \end{forest} \\
     \hline \begin{forest} [$\phi \lor \psi$ [$\phi$][$\psi$]] \end{forest}& \begin{forest} [$\neg (\phi \lor \psi)$ [$\neg \phi$ [$\neg \phi$]]] \end{forest}  & \begin{forest} [$\phi \imply \psi$ [$\neg \phi$][$\psi$]] \end{forest}\\
      \hline \begin{forest} [$\neg (\phi \imply \psi)$ [$\phi$ [$\neg \psi$]]] \end{forest}& \begin{forest} [$\phi \ffi \psi$ [$\phi$ [$\psi$]] [$\neg \phi$ [$\neg \psi$]]] \end{forest}& \begin{forest} [$\neg (\phi \imply \psi)$ [$\phi$ [$\neg \psi$]] [$\neg \phi$ [$\psi$]]]\end{forest} \\
      \hline
    \end{tabular}
  \end{table}
  \end{center}
  Le but du jeu avec un arbre logique, c'est de terminer chacune des branches de l'arbre par $\bot$ (C'est le symbole utilisé pour les contradictions). Ainsi, avec un arbre, nous commençons par utiliser l'opposé de notre hypothèse de base (ici, l'opposé de $\neg (A \land B) \ffi \neg A \lor \neg B$, c'est $\neg (\neg (A \land B) \ffi \neg A \lor \neg B)$), (en général, une contradiction arrive quand nous nous retrouvons avec $A$ et $\neg A$ sur la même branche.) \\
  Passons maintenant à la preuve
  \begin{center}
  \begin{forest}
  [$\neg (\neg (A \land B) \ffi \neg A \lor \neg B)$
    [$\neg(A \land B)$
    [$\neg (\neg A \lor \neg B)$
    [$A$
    [$B$
    [$\neg A$
    [$\bot$]]
    [$\neg B$
    [$\bot$]]]]]]
    [$\neg (\neg (A \land B))$
    [$ \neg A \lor \neg B$
    [$A \land B$
    [$A$
    [$B$
    [$\neg A$
    [$\bot$]]
    [$\neg B$
    [$\bot$]]]]]]]]
  \end{forest}
\end{center}
Chaque branche de l'arbre fini bien par $\bot$, nous venons donc de prouver la loi de DeMorgan, avec l'aide de notre arbre de démonstration. \\[1.0cm]
    Ci dessous, le lecteur pourra s'essayer à la démonstrations de certaines lois logiques célèbres, avec l'aide d'un tableau ou avec un arbre. \\[1.0cm]
  \begin{equation}\neg \neg A \ffi A \end{equation}
  \begin{equation} A \land \neg A \ffi F \end{equation}
  \begin{equation} A \lor \neg A \ffi T \end{equation}
  \begin{equation} A \land F \ffi F \end{equation}
  \begin{equation} A \lor V \ffi V \end{equation}
  \begin{equation}
    \begin{cases}
      A \lor B \ffi B \lor A \\
      A \land B \ffi B \land A
    \end{cases}
  \end{equation}
  \begin{equation}
    \begin{cases}
      A \land (B \land C) \ffi (A \land B) \land C \\
      A \lor (B \lor C) \ffi (A \lor B) \lor C
    \end{cases}
  \end{equation}
  \begin{equation}A \land (B \lor C) \ffi (A \land B) \lor (A \land C) \end{equation}
  \subsection{Les ensembles de propositions.}
  Les ensembles de propositions, comme leur nom l'indique, sont des ensembles mathématiques, composés de {\bf formules logiques}.
  Ces formules sont dites soit: \\
  \begin{itemize}
  \item {\bf consistantes}, signifiant qu'il est possible d'en tirer du Vrai, par exemple $A \land B$ ou encore $\neg \neg A \imply A$.
  \item {\bf inconsistances}, signifiant que l'on ne peut en tirer que du Faux, par exemple $A \land \neg A$, ces formules peuvent être notées $\bot$.
  \item {\bf valides}, signifiant qu'elles ne peuvent être que Vraies, comme $A \lor \neg A$ (principe du tiers-exclus), une formule {\bf valide} est par définition toujours {\bf consistante}, on appelle bien souvent ces formules valides des {\bf tautologies}, ces formules pourront être notées $\top$. \\
  \item {\bf contingentes}, impliquant que l'on peut tirer de la formule du faux, tout comme du vrai, une {\bf tautologie} ne peut pas être formule contingente,
  un exemple de formule contingente serait $A \lor B$.
  \end{itemize}

  Les ensembles aussi ont leur propre terminologie, ainsi, si l'on prend l'ensemble noté $S$, il pourra être qualifié également de {\bf consistant}, si il n'y a pas de contradictions au sein de $S$ et qu'il n'y a aucune formule inconsistante contenue dans $S$, autrement $S$ sera défini comme étant {\bf inconsistant}. \\[0.5cm]
  Il y a plusieurs manières d'{\bf inférer} quelque chose d'un ensemble logique. \\
  Une première manière est de prendre les {\bf prémisses} qui nous intéressent, et d'écrire \\[0.5cm]
    1. {\bf Premisse\_A} \\
    2. {\bf Premisse\_B} \\
    \hspace{0.2cm}$\vdots$ \\
    n. {\bf Premisse\_X} \\
    \hspace{0.5cm}\line(1, 0){60} \\
    $\therefore$ {\bf Conclusion} \\[0.5cm]
  Prenons un ensemble {\bf consistant} $S$ composé des formules $A$ et $A \imply B$. \\
  On pourrait alors noter $S$ comme étant $S = \{ A, A \imply B \}$ (ce qui est parfaitement équivalent à écrire $S = A \land (A \imply B)$), \\
  De ceci, nous allons utiliser l'opérateur de la déduction, $\vDash$, ceci nous permettra ainsi écrire $S \vDash A$, littéralement ``De $S$, nous déduisons $A$''. \\Ce principe est encore plus flagrant quand nous utilisons la notation suivante : $A, A \imply B \models A$, où $A, A \imply B$ n'est autre que l'ensemble S, avec une notation légèrement différente. \\[0.5cm]

  Je n'ai pas choisi cet ensemble de manière anodine, car, grâce à celui-ci, nous allons pouvoir utiliser une {\bf règle d'inférence} connue sous le nom du MP (Modus Ponens), le lecteur ne devrait toutefois pas s'inquiéter, un tableau recensant d'autres règles d'inférence sera présenté à la page suivante. \\
  Une première manière de noter cette règle d'inférence serait de faire usage de la notation que nous avons vue plus haut. \\[0.5cm]
    1. A (De cet ensemble, nous savons A) \\
    2. $A \imply B$ (De cet ensemble, nous savons que $A \imply B$) \\
  \hspace{10cm}\line(1, 0){60} \\
  $\therefore$ B \\[0.5cm]
  Une autre manière serait d'utiliser l'opérateur $\vDash$ (celui de la {\bf déduction}), de la manière suivante : $A, A \implies B \vDash B$, nous pourrions même être tentés d'utiliser la {\bf règle d'addition}, disant que si l'on a $S \vDash B$, alors, on peut rajouter la formule B à S. Et ainsi, notre ensemble S de base pourra être réécrit en $S = {A, A \imply B, B}$
  Et maintenant, comme promis, voici un tableau comprenant toutes les règles d'inférence qui seront bien pratiques pour travailler avec les ensembles logiques.
  \FloatBarrier
  \begin{adjustwidth}{300pt}{0pt}
    \begin{table}[H]
    \begin{tabular}{|c|M{5.0cm}|p{5.0cm}|}
      \hline Règle d'inférence & Tautologie & Nom de la règle d'inférence \\
      \hline $A, B \vDash A \land B$ & $A \land B \imply A \land B$& Loi de combinaison \\
      \hline $A, B \vDash A$ & $(A \land B) \imply A $& Loi de la simplification \\
      \hline $A, A \imply B \vDash B$ & $A \land (A \imply B) \imply B $ & Modus Ponens \\
      \hline $\neg B, A \imply B \vDash \neg A$ & $\neg B \land (A \imply B) \imply \neg A$ & Modus Tollens \\
      \hline $A \imply B, B \imply C \vDash A \imply C$ & $(A \imply B) \land (B \imply C) \imply (A \imply C)$ & Syllogisme hypothétique \\
      \hline $A \lor B, \neg A \vDash A$ & $(A \lor B) \land \neg A \imply B$ & Syllogisme disjonctif \\
      \hline $A \imply B \vDash A \imply (A \land B)$ & $(A \imply B) \imply (A \imply (A \land B)$ & Règle d'absorption \\
      \hline $A \imply B, C \imply B, A \lor C \vDash B$ & $(A \imply B) \land (C \imply B) \land (A \lor C) \imply B$ & Elimination disjonctive\\
      \hline $A, \neg A \vDash B$ & $A \land \neg A \imply B$ & Principe d'explosion \\
      \hline
    \end{tabular}
  \end{table}
\end{adjustwidth}
\FloatBarrier
Le lecteur pourra s'exercer à démontrer la validité des tautologies présentées dans le tableau-ci dessus en tant qu'exercice. \\
\subsubsection{Le besoin d'algorithme, présentation de l'algorithme de Quine.}

Un ensemble de formules, tout comme une formule peut-être inconsistant, cela signifie que notre ensemble est équivalent à F,et comme nous l'avons vu dans le tableau ci-dessus, on peut déduire absolument n'importe quoi d'un ensemble inconsistant.\\

Le problème des tableaux de vérités, c'est qu'ils prennent de la place, et même, beaucoup de place. C'est pour cela qu'est venu la nécessité de créer des algorithmes de résolution d'ensembles de formules, afin de faciliter le travail des logiciens, et ainsi, de réduire le temps de calcul nécessaire à un ordinateur. \\

L'algorithme de Quine se déroule en plusieurs étapes, tout d'abord, nous allons simplifier, si possibles, les formules logiques contenues dans notre ensemble de formules, par exemple, au lieu d'écrire $A \lor V$, nous pourrons écrire simplement $ V $, et ainsi, supprimer ce $V$ de notre ensemble, comme $B, V \models B$, il y a bien d'autres simplifications possibles, nous laisserons au lecteur le soin d'en trouver.\\

Une fois cette première étape passée, il suffit d'utiliser un arbre logique (ou éventuellement une table de vérité) et enfin, nous avons pu prouver des formules logiques avec l'aide de l'agorithme de Quine.
\subsection{Une logique? Des logiques!}
Les logiciens, non-contents de la seule logique propositionnelle, ont créée un très grand nombre de logique, j'en liste quelques une ci-dessous.
\begin{itemize}
  \item La logique linéaire, créée par un français, elle est basée sur la gestion de ressources, c'est une des nombreuses logiques n'excluant pas le tiers exclus, en effet, en logique linéaire, $A \lor \neg A \nvDash V$, cela est simplement du au fait que nous ``utilisons'' la ressource A une fois, elle n'existe donc plus réellement, et donc $\neg A$ n'existe pas comme A est devenu indéterminé.
  \item La logique floue, dans laquelle une proposition est vraie selon un certain degré de probabilité.
  \item La logique de premier ordre, ou logique des prédicats, cette logique sera abordée dans le chapître sur Prolog.
  \item La logique booléenne, elle est basée sur les portes logiques, les circuits logiques, et les ensembles.
  \item La logique combinatoire, logique inventée pour formaliser la notion de fonction, et pour limiter le nombre d'opérateurs nécessaires pour définir le calcul des prédicats.
  \item La logique modale, ayant recours à des opérateurs comme ``il est nécessaire que'' ou ``il est possible que''.
  \item Et bien d'autres...
\end{itemize}
\vfill
\subsection{Introduction à Prolog et à la logique des Prédicats.}
Dans cette nouvelle sous-section, nous allons nous intéresser à la logique des prédicats, connue également sous le nom de logique de premier ordre. \\
Tout d'abord, en logique des prédicats, nous aurons besoin de deux nouveaux {\bf quantificateurs}. \\
Ceux-ci sont le quantificateur {\bf universel}, noté $\forall$ [lisez ``pour tout''], et le quantificateur {\bf existentiel}, noté $\exists$ [lisez ``il existe'']. \\
A ces deux quantificateurs viennent s'ajouter:
\begin{itemize}
  \item Des {\bf connecteurs logiques}, qui ont été discutés dans la section précédente.
  \item Des {\bf constantes}, celles-ci représentent un événement, une personne ou un objet en particulier, nous noterons ces constantes avec une majuscule comme première lettre et un nombre à la fin, par exemple ``Turing\_1'' ou encore ``Chaise\_2''.
  \item Des {\bf variables}, celles-ci représentent un concept général ou un ensemble, par exemple, l'ensemble des mathématiciens, ou encore l'ensemble des chaises dans le monde. Nous noterons ces variables en minuscules, par exemple ``mathématiciens'' ou encore ``chaise''.
  \item Des {\bf prédicats}, ceux-ci nous permettent d'établir des liens entre nos différentes variables et constantes, nous noterons nos prédicats avec une majuscule en première lettre, par exemple ``{\bf Mortel}(x)'' ou encore ``{\bf Humain}(x)''.
  \item Des {\bf fonctions}, qui ont pour but de retourner une valeur, pouvant-être autre chose que vrai ou faux. Nous noterons celles-ci en toutes minuscules.
\end{itemize}
\subsubsection{Exemples.}
Pour se faire une bonne idée, voici quelques phrases françaises ``traduites'' en logique des prédicats. \\[0.5cm]
1. Tout les mathématiciens sont cools. \\
=$>$ $\forall$x ({\bf Mathématicien}(x) $\imply$ {\bf Cool}(x)). \\[0.2cm]
2. Alan Turing et Alonzo Church sont des mathématiciens. \\
=$>$ {\bf Mathématicien}(Turing\_1) $\land$ {\bf Mathématicien}(Church\_1). \\[0.2cm]
3. Il y a des chats qui ne sont pas noirs. \\
=$>$ $\exists$x ({\bf Chat}(x) $\land$ $\neg${\bf Noir}(x)). \\[0.2cm]

\subsubsection{Qu'est-ce que PROLOG?}
Cette petite introduction passée, concentrons-nous maintenant sur le coeur du sujet: PROLOG! \\

Prolog a été inventé en 1972 par les informaticiens français Alain Colmerauer et Philippe Roussel. \\
C'est un langage de programmation {\bf logique} et son nom est un acronyme pour PROgrammation LOGique. \\
Prolog a été très utilisé en Europe et au Japon dans le domaine de l'Intelligence Artificielle, tout en étant basé sur la logique propositionnelle dont nous avons posé les bases juste au dessus. \\
Il existe de nombreuses distributions de PROLOG\footnote{https://en.wikipedia.org/wiki/Comparison\_of\_Prolog\_implementations}, nous utiliserons ici SWI-PROLOG, avant tout pour son côté open-source et gratuit.
\subsubsection{Introduction à la syntaxe de Prolog}
En Prolog, contrairement aux règles que nous avions établies en logique des prédicats, les constantes (ici appelés Atomes) doivent commencer par une minuscule. Les variables commencent par une majucule. A cela viennent s'ajouter les listes, dénotées par des []. \\

\underline{{\bf Faits et Règles.}} \\[0.2cm]
En PROLOG, un fait s'écrit simplement \\[0.2cm]

Un fait n'a pas de ``corps'', et tiendra toujours. Dans ce cas-ci, cela veut dire que Turing est un mathématicien, quoiqu'il arrive ce {\bf fait} ne changera pas. \\

Maintenant, si nous essayons de reformuler l'exemple n°1 de notre dernière section, ``tout les mathématiciens sont cools'' en Prolog, cela donne ceci : \\[0.2cm]

On remarque tout de suite que cela est plutôt facile à lire, de plus, si nous ouvrons notre interprète Prolog, voilà ce que nous obtenons: \\[0.2cm]

Tout cela est très bien, mais, si j'essaye de demander à prolog si alonzo\_church est cool, que se passe-t-il? \\[0.2cm]
Pas grand chose comme nous le constatons, PROLOG préfère éviter de faire la moindre assomption, et répondra ``Faux'' dès qu'il ne sait pas. \\

Ensuite, Prolog nous permet de faire de l'arithmétique, regardons un peu cela, avec une fonction dont le seul rôle est d'additionner deux nombres: \\[0.2cm]
Ouvrons maintenant l'interprète et regardons la magie opérer: \\[0.2cm]

Mais, si pour une obscure raison, je décidais de vouloir avoir B, juste en entrant A et C, comment faire? Regardons d'abord comment notre première version réagirait à cela: \\[0.2cm]

Heureusement pour nous, Prolog possède un module basé sur la logique par contraintes, pour l'utiliser, il suffit d'ajouter\footnote{https://www.swi-prolog.org/man/clpfd.html} \\[0.2cm]

au dessus de votre fichier Prolog, maintenant, modifions légèrement notre prédicat \\[0.2cm]
Et voilà! Essayons là maintenant avec notre interprète: \\[0.2cm]

\subsubsection{Mon arbre familial, avec Prolog!}

% L'exemple sera mis juste après.
\newpage
\section{L'approche algorithmique.}
\subsection{Qu'est-ce qu'un algorithme?}
\begin{center}
  \framebox{Un algorithme est une suite d'instructions permettant de résoudre un problème.}
\end{center}

Il faut savoir que nous utilisons des algorithmes bien plus souvent que ce que l'on pourrait croire. Par exemple, quand vous préparez un gâteau pour célébrer une quelconque occasion, vous aurez besoin d'une recette. Cette recette n'est autre que l'algorithme aidant à la préparation du gâteau, chaque étape de la recette n'étant qu'une instruction faisant partie de l'algorithme. \\[0.2cm]
Un des tout premiers exemples d'algorithmes est ``l'agorithme d'Euclide'', celui-ci permettait de trouver le PGCD de deux nombres. \\
Voici comment celui-ci fonctionne: \\[0.2cm]
\begin{itemize}
  \item Tout d'abord, nous prenons deux nombres a et b.
  \item Si b = 0 alors, nous retournons a comme étant le pgcd.
  \item Sinon, nous écrivons que {\bf pgcd}(a, b) = {\bf pgcd}(b, a {\bf mod} b)\\[0.2cm]
\end{itemize}
Et en voici sa traduction en Common Lisp, le langage de programmation que nous utiliserons dans cette partie du dossier.
\lstinputlisting[language=Lisp]{gcd.lisp}

\subsubsection{La complexité des algorithmes}
Evidemment, tout les algorithmes ne se valent pas, certains sont bien plus lents que d'autres, et ce, pour une seule et même tâche.\\
Pour juger de la {\bf complexité} d'un algorithme, nous utilisons la notation de Landau (dite du ``Big-O'' en anglais). \\
Cette notation a pour but d'estimer l'évolution du nombre d'opérations qui seront effectuées par l'algorithme au cours du temps. Car au plus l'algorithme effectue d'opérations, au plus il sera couteux en temps, ce qui n'est pas pour nous arranger. \\[0.5cm]
Pour montrer l'importance d'avoir des algorithmes performants, nous avons implémentés en Lisp deux algorithmes de tris différents: \\[0.2cm]
\begin{itemize}
  \item Le {\bf tri à bulles} de complexité {\bf $O(n^{2})$}
  \item Le {\bf tri par fusion} de complexité {\bf $O(n\log{n})$}\\
\end{itemize}
Le {\bf tri à bulles} fonctionne de la manière suivante:
\begin{itemize}
  \item Prendre les deux premiers éléments de la liste.
  \item Si le premier est plus grand que le second, les échanger, sinon, les laisser en place.
  \item Faire de même jusqu'à la fin de la liste.
  \item Une fois arrivé à la fin de la liste, reprendre à partir du début de la liste.
  \item Continuer ce procédé jusqu'à ce que la liste soit parfaitement rangée.\\[0.2cm]
\end{itemize}
Il est implémenté de la manière suivante en Common Lisp: \\[0.2cm]
\lstinputlisting[language=Lisp]{bubble_sort.lisp}
Le {\bf tri par fusion} marche de manière assez différente:
\begin{itemize}
  \item Si le tableau n'a qu'un seul élément, il est considéré comme déjà trié.
  \item Si il a plus d'un élément, séparer le tableau en deux parties à peu près égales.
  \item Trier les deux parties ainsi séparées.
  \item Fusionner les deux tableaux triés en un seul tableau trié. \\[0.2cm]
\end{itemize}
La fonction merge étant prédéfinie en common Lisp, nous implémenterons notre tri par fusion ainsi.
\lstinputlisting[language=Lisp]{merge_sort.lisp}
Passons maintenant aux {\bf tests de performances}. \\
Afin de mesurer le temps pris par chacun de mes deux algorithmes, j'ai utilisé ``time'', une macro bien pratique pour ce genre de tests. J'utilise le compilateur SBCL pour faire mes tests. En plus de cela, dans un soucis de facilité, j'utilise la macro random-sample, créée par mes soins, me permettant de créer une liste contenant des nombres aléatoires, de taille fixée. \\
\begin{lstlisting}[language=Lisp]
;;; Ma macro random-sample bien pratique.
(defmacro random-sample (x)
   (loop for _ below ,x collect (random 1000)))
\end{lstlisting}
Sans plus attendre, voici le tableau montrant les résultats de notre petite expérience.
\begin{table}[H]
  \begin{tabular}{|c|c|c|}
    \hline {\bf Nombre d'éléments à triers.} & {\bf Temps Tri à Bulles.} & {\bf Temps Tri par fusion.} \\
    \hline 10 & 0.0000008 secondes & 0.000016 secondes \\
    100 & 0.000089 secondes & 0.000140 secondes \\
    1000 & 0.007863 secondes & 0.001188 secondes \\
    10,000 & 0.318904 secondes & 0.012558 secondes \\
    100,000 & 31.164620 secondes & 0.090092 secondes \\
    \hline
  \end{tabular}
\end{table} \smallskip
Pour des raisons pratiques, je n'ai pas pu obtenir les résultats du Tri à Bulles pour le million d'éléments. \\
Comme nous pouvons le constater sur le tableau précédent, la complexité d'un algorithme (estimé par le Big-O) ne mesure pas le temps exact que l'algorithme prendra afin de trier une certaine liste, il s'agit simplement d'un indicateur, montrant comment évoluera le nombre de comparaisons au cours du temps, cet indicateur devenant extrêmement siginificatif quand n devient très grand. \\[0.5cm]
\subsection{Présentation de structures de données de base}
Pour produire une intelligence artificielle efficace, il nous faut de bons algorithmes, mais il nous faut également les structures de données adéquates. \\
Tout d'abord, qu'est-ce qu'une structure de données?
D'après Wikipedia\footnote{https://fr.wikipedia.org/wiki/Structure\_de\_donn\%C3\%A9es}, une structure de données est une manière d'organiser les données, pour les traiter plus facilement. \\
On conclut donc que le choix judicieux d'une structure de données est indispensable à l'optimisation de la performance de notre IA.

Je présente ici trois structures de données de base.
\begin{enumerate}
  \item Les listes simplement chaînées.
  \item Les tableaux (ou arrays en anglais.)
  \item Les tables de hachages (ou les dictionnaires.) \\[0.2cm]
\end{enumerate}

\subsubsection{Les listes simplement chaînées.}
Une {\bf liste simplement chaînée} est une structure de données pouvant contenir plusieurs éléments. Chaque élément appartenant à la liste chaînée contient deux choses:
\begin{enumerate}
  \item La valeur de l'élément.
  \item Un pointeur pointant vers l'élément suivant. \\[0.2cm]
\end{enumerate}

Ainsi, nous pouvons représenter une liste simplement chaînée de la manière suivante \\[0.5cm]

% TODO: INSÉRER IMAGE LISTE SIMPLEMENT CHAINÉE.
En Lisp, une liste simplement chaînée peut être crée de la manière suivante. \\[0.2cm]
\begin{lstlisting}[language=Lisp]
(defparameter *my-linked-list* '(1 2 3 4 5))
\end{lstlisting}
Ainsi, si nous reprenions le dessin que nous avions utilisé ci-dessus,
*my-linked-list* ressemblera donc à ceci: \\[0.5cm]

% TODO: INSERER IMAGE *MY-LINKED-LIST*

D'ailleurs, pour pouvoir travailler avec des listes chaînées, deux opérateurs bien pratiques s'offrent à nous: ``car'' et ``cdr''. \\[0.2cm]
\begin{lstlisting}[language=LISP]
CL-USER> (car *my-linked-list*)
1
CL-USER> (cdr *my-linked-list*)
(2 3 4 5)
\end{lstlisting}
Nous pouvons également chaîner nos opérateurs ``car'' et ``cdr'', afin de nous assurer un contrôle total sur notre liste simplement chaînée.
\begin{lstlisting}[language=LISP]
CL-USER> (car (cdr *my-linked-list*))
2
CL-USER> (cadr *my-linked-list*) ; Il existe aussi une manière abrégée.
2
\end{lstlisting}
Il existe également la fonction ``nth'', permettant de récupérer le n-ième élément d'une liste chaînée. (Il ne faut pas oublier que l'indexing marche comme pour les tableaux, et commence à 0.)
\begin{lstlisting}[language=LISP]
CL-USER> (nth 2 *my-linked-list*)
3
\end{lstlisting}

\subsubsection{Les tableaux.}
Le tableau est une structure extrêmement importante en programmation,
celle-ci nous permet de stocker un nombre fixe de données, et nous permet d'accéder à ces données de manière rapide. Chaque élément du tableau se retrouve collé en mémoire aux éléments qui lui sont adjacent, ainsi, pas besoin de traverser chaque élément du tableau lorsque l'on désire accéder au n-ième élément du tableau. \\[0.2cm]
Voici comment créer un tableau en Lisp:
\begin{lstlisting}[language=Lisp]
  CL-USER> (defparameter *my-array* #(1 2 3 4 5))
\end{lstlisting}
Il existe également une manière alternative:
\begin{lstlisting}[language=Lisp]
  CL-USER> (defparameter *my-array* (make-array 5 :initial-contents '(1 2 3 4 5)))
\end{lstlisting}
Pour récupérer le n-ième élément d'un tableau, il nous suffit de faire:
\begin{lstlisting}[language=Lisp]
  CL-USER> (aref *my-array* 2)
  3
\end{lstlisting}
\subsubsection{Tableaux vs Listes simplement chaînées.}
Pour en conclure avec ces deux structures de données, je me propose de faire un petit tableau comparatif final, afin que le lecteur puisse mieux comprendre les différennces entre Tableau, et Liste simplement chaînée, (que je noterai SLL pour Single-linked list).
\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline & Tableaux & SLL \\
    \hline {\bf Accession} & O(1) & O(n) \\
    \hline {\bf Insertion} & O(n) & O(1) \\
    \hline {\bf Délétion}  & O(n) & O(1) \\
    \hline
  \end{tabular}
\end{table} \smallskip
Comme on le constate sur ce tableau, les arrays ont un réel avantage lorsque nous désirons uniquement lire un élément de notre structure de données, toutefois, si nous désirons modifier la structure de données en elle-même, alors, tout devient plus problématique, et cela, car notre tableau devra retrouver un autre emplacement libre pour s'y mettre en mémoire. \\
La liste chaînée quant à elle, n'a pas besoin de se repositionner entièrement lorsqu'on lui ajoute ou qu'on lui retire un élément, il lui suffit plutôt de rajouter un pointeur vers le nouvel élément, ce qui se fait en temps constant (O(1)), peu importe la taille de la liste. Toutefois, la liste chaînée a pour inconvénient d'être en croissance linéaire lors de la recherche d'un élément dans la liste, en effet, lors de la recherche d'un élément dans une liste chaînée, le programme devra d'abord passer par tout les éléments se trouvant avant celui que l'on cherche. \\
Pour démontrer l'importance d'utiliser la bonne structure au bon endroit, nous allons reprendre notre bon tri à bulles. \\
Pour ceux qui en avaient oublié l'implémentation sur les tableaux, la voici:
\lstinputlisting[language=Lisp]{bubble_sort.lisp}
Le lecteur attentif remarquera l'utilisation dans ce code de ``make-array'' et de ``aref'', tout deux synonymes de l'utilisation d'un tableau. Maintenant, transformons cette implémentation en une implémentation utilisant des listes simplement chaînées. \\
Et maintenant, voici le même algorithme, mais, sur les listes simplement chaînées cette fois-ci.
\lstinputlisting[language=Lisp]{bad_bubble_sort.lisp}
Et maintenant, comparons leurs temps respectifs sur des listes de tailles différentes avec l'aide d'un nouveau tableau, (mon mode opératoire reste le même, j'utilise SBCL, et la macro time, pour créer une liste contenant des nombres aléatoires, j'utilise toujours ma macro random-sample.)
\begin{table}[H]
  \begin{tabular}{|c|c|c|}
    \hline & Tri à bulles (Tableaux) & Tri à bulles (SLL) \\
    \hline 10 &  0.0000008 secondes &  0.000009 secondes \\
    \hline 100 &  0.000089 secondes &  0.002111 secondes \\
    \hline 1000 & 0.007863 secondes &  0.750918 secondes \\
    \hline 10000 & 0.318904 secondes & 888.190640 secondes \\
    \hline 100000 &  31.164620 secondes & $>$1000 secondes \\
    \hline
  \end{tabular}
\end{table}
La différence de performance entre nos deux implémentations du même algorithme est énorme, et pourtant, nous n'avons pas changé l'algorithme en lui-même! J'espère que notre petite expérience montre bien au lecteur l'importance d'un choix de structure de données adéquat.
\subsubsection{Les tables de hachages.}
Une table de hachage (ou un dictionnaire en python) est une des structures de données les plus utiles en ce qui concerne l'optimisation d'algorithmes. \\
Son utilisation est simple; avec une table de hachage, nous relions des clés avec des valeurs. \\ Ainsi, si dans une table de hachage, je relie le mot ``bonjour'' avec le mot ``hello'', mon mot ``bonjour'' sera considéré comme étant la clé, et le mot ``hello'' comme étant la valeur. \\
En Lisp, pour créer une telle table de hachage, il faut faire: \\
\begin{lstlisting}[language=Lisp]
CL-USER> (defparameter *my-dict* (make-hash-table))
*MY-DICT*
CL-USER> (setf (gethash 'bonjour *my-dict*) 'hello)
HELLO
CL-USER> (gethash 'bonjour *my-dict*)
HELLO
\end{lstlisting}
Ce procédé étant toutefois un peu fastidieux, nous utiliserons ici la bibliothèque lisp connue sous le nom de serapeum. \\
\begin{lstlisting}[language=Lisp]
CL-USER> (ql:quickload :serapeum) ;; Ici, nous déclarons la bibliothèque.
To load "serapeum":
  Load 1 ASDF system:
    serapeum
; Loading "serapeum"
.
Switching to the BALLAND2006 optimizer

(:SERAPEUM)
CL-USER> (defparameter *my-dict* (serapeum:dict 'bonjour 'hello))
*MY-DICT*
CL-USER> (gethash 'bonjour *my-dict*)
HELLO
\end{lstlisting}
Pour montrer un cas pratique d'utilisation de tables de hachages, nous allons créer un mini-programme qui permet de convertir des phrases en morse. \\
Ce programme se fait en deux parties, tout d'abord, nous définissons une table de hachage qui nous remet la traduction morse de chaque lettre et de chaque chiffre. \\
\begin{lstlisting}[language=Lisp]
(ql:quickload :serapeum)

(defparameter *latin->morse*
  (serapeum:dict #\a "._" #\b "_..." #\c "_._." #\d "_.."
                 #\e "." #\f ".._." #\g "__." #\h "...."
                 #\i ".." #\j ".___" #\k "_._" #\l "._.."
                 #\m "__" #\n "_." #\o "___" #\p ".__."
                 #\q "__._" #\r "._." #\s "..." #\t "_"
                 #\u ".._" #\v "..._" #\w ".__" #\x "_.._"
                 #\y "_.__" #\z "__.." #\1 ".____" #\2 "..___"
                 #\3 "...__" #\4 "...._" #\5 "....." #\6 "_...."
                 #\7 "__..." #\8 "___.." #\9 "____." #\0 "_____"
                 #\SPACE " "))
\end{lstlisting}
Voici notre dictionnaire! Ne soyez pas surpris par les ``\#\'', c'est ainsi que nous définissons des charactères en common lisp. \\
Maintenant, la deuxième partie consistera simplement à créer une fonction chargée de transformer nos phrases vers du morse. \\
\begin{lstlisting}[language=Lisp]
(defun convert-to-morse (sentence)
  "Cette fonction s'occupe de convertir
nos phrases vers du code Morse, grâce au dictionnaire
créé ci-dessus!"
  (let ((converted-list
          (loop for letter across sentence
                collect (gethash letter *latin->morse*))))
  (format nil "~{~A~}" converted-list)))
\end{lstlisting}
Il ne nous reste plus qu'à tester.
\begin{lstlisting}[language=Lisp]
CL-USER> (convert-to-morse "ceci est une phrase")
"_._.._._... ...._ ..__.. .__......_.._...."
\end{lstlisting}
Et voilà comment notre programme marche! \\
Petite parenthèse au niveau de la complexité de notre fonction ``convert to morse''. Tout d'abord, il faut savoir que pour chercher une valeur avec une clé dans un dictionnaire, la complexité temporelle est de O(1)! Peu importe la taille du dictionnaire, cela prendra toujours aussi peu de temps de chercher une clef dedans, c'est la raison pour laquelle ceux-ci sont très utilisé de nos jours.
Pour les lecteurs intéressés, nous conseillons fortement de vous renseigner sur la fonction SHA, c'est grâce à cette fonction de hachage que les dictionnaires marchent aussi bien. \\
Ainsi, pour en revenir à notre programme, nous appliquons une opération de complexité O(1) sur chaque élément de notre liste, soit, n fois. On peut donc en déduire que notre fonction ``convert-to-morse'' est donc de complexité O(n), car nous appliquons n fois une opération de complexité O(1). \\[0.2cm]
\subsubsection{Promenons-nous dans les bois.}
Pour comprendre l'intérêt des arbres dichotomiques en programmation, intéressons nous à un petit problème assez simple. \\
Imaginez que je pense à un nombre, compris entre 1 et 1000, et que vous deviez deviner ce nombre avec le moins d'essais possibles, à la même manière que dans le jeu du ``Juste Prix'', je vous dirai si votre essai est trop grand, ou trop petit. \\
La première stratégie évidente, serait de commencer par 1, puis ensuite, si mon nombre n'est pas 1, essayer avec 2, puis ensuite, essayer avec 3, et ceci, jusqu'à ce que vous trouviez le nombre auquel je pense. \\
Cette première stratégie pourrait faire penser à la manière à laquelle il faut chercher un élément dans une liste simplement chaînée, en effet, si je pense au nombre 629, il va falloir passer par les 628-ièmes éléments se trouvant avant. Dans ce cas-ci, comme pour lire un élément dans une liste simplement chaînée, nous dirons que la complexité de cet algorithme sera de O(n). \\
Une deuxième manière de faire serait de faire ce que l'on appelle une recherche dite ``par dichotomie''. Tout d'abord, prenons un nombre au milieu entre 1 et 1000, ici, ce sera 500, si je dis ``au dessus'', alors, il suffira de prendre le milieu entre 500 et 1000, ici, ce sera 750, désormais, si je dis ``en dessous'', il faudra alors faire $\frac{500 + 750}{2} = 625$, ainsi, en appliquant cet algorithme jusqu'au bout, vous trouverez le nombre auquel je pense en utilisant un algorithme de complexité O(log n)! \\ Ainsi, vous trouverez grâce à cette technique le nombre auquel je pense en maximum $\log_{2}{n}$ essais (où n est le nombre maximum, qui est ici 1000). \\
J'espère que cette petite explication aura pu expliquer au lecteur le fonctionnement d'une recherche par dichotomie. Maintenant, pour ce qui est de l'implémentation d'une telle recherche en Lisp: \\
\lstinputlisting[language=Lisp]{dichotomia.lisp}
Plus qu'à la tester!
\begin{lstlisting}[language=Lisp]
[1] CL-USER> (binary-search 1 1000)
500?
plus-haut
750?
plus-bas
625?
plus-haut
687?
plus-bas
656?
plus-bas
640?
plus-bas
632?
plus-bas
628?
plus-haut
630?
plus-bas
629?
oui
Ton nombre a été trouvé en 9 essais
\end{lstlisting}

Cette petite introduction à la recherche par dichtomie servait surtout à donner une intuition au lecteur de l'importance des arbres binaires. \\
Ceux-ci fonctionnent d'une manière similaire à notre recherche dichotomique. \\
Sur un arbre binaire, chaque noeud est soit relié à rien (ou ``nil''), soit relié à sa ``gauche'' à un noeud contenant une valeur plus petite que celle de son noeud parent, soit relié à sa ``droite'' à un noeud contenant une valeur plus grande que celle de son noeud parent. Nous pouvons donc représenter un arbre binaire ainsi: \\[0.2cm]

\subsection{Qu'est-ce que Lisp?}
Lisp est une famille de langages de programmation fonctionnels, inventés en 1958 par John McCarthy (l'homme ayant inventé le terme ``intelligence artificielle''). \\
Ceux-ci sont reconnaissables facilement grâce au très grand nombre de parenthèses présentes dans chacun des dialectes de Lisp. \\
Aujourd'hui, le dialecte Lisp le plus utilisé reste {\bf Clojure}, toutefois, il en reste d'autres gardant toujours leur cote de popularité, pour n'en citer que quelques-un, nous avons
\begin{itemize}
  \item {\bf Scheme}, qui est un dialecte très minimaliste de Lisp, très utilisé au niveau académique.
  \item {\bf Emacs Lisp}, un dialecte très pratique pour tout ceux désirant configurer l'éditeur de texte Emacs.
  \item {\bf Racket}, un super-set de Scheme.
  \item {\bf Common Lisp} est le dialecte que nous utiliserons ici, ce dialecte a toujours eu la réputation d'être plus orienté vers les applications pratiques, et n'a jamais reçu de grandes faveurs académiques. Common Lisp a toutefois le mérite d'avoir été standardisé, de bénéficier d'un système orienté-objet connu sous le nom de CLOS.
\end{itemize}
\subsubsection{Les bases de Lisp.}
\subsubsection{Programme Lisp pour résoudre parfaitement le jeu de Nim.}
\subsection{Le pathfinding.}
\subsubsection{Présentation du problème.}
\subsubsection{L'algorithme de Dijkstra.}
\subsubsection{Le besoin d'heuristiques.}
\subsubsection{Dijkstra avec de l'heuristique: A*!}

\subsection{Des programmes et des jeux!}
\subsubsection{L'agorithme Minimax.}
\subsubsection{$\alpha\beta$-élagage.}
\subsubsection{Du dynamisme bon sang!}
\subsection{Un programme de jeu.}
\newpage
\section{Le Machine Learning.}
\subsection{Définition du Machine Learning}
Le Machine Learning, ou Apprentissage Automatique, est un type d'intelligence artificielle qui avec les données à analyser et sur lesquelles s'entraîner permet aux ordinateurs d’apprendre par expérience sans avoir été explicitement programmé à cet effet ou par intervention humaine. Cela consiste en algorithmes d’apprentissage qui améliorent leur performance à exécuter des tâches au fil du temps grâce à de l’expérience.\\[1.0cm]
\subsection{Les Maths dans le Machine Leanring.}
\begin{enumerate}
  \item De nombreux data scientists (chargés de la gestion, de l’analyse et de l’exploitation des données au sein d’une entreprise) considèrent le machine Learning comme un apprentissage statistique.
  \item Matrice et algèbre matricielle, exemple :
        \begin{enumerate}
          \item Les suggestions d’amis sur Facebook
          \item Recommandation de vidéo sur Facebook
          \item $\cdots$
        \end{enumerate}
  \item Fonction, variable, équation et graphique, ...
\end{enumerate}

\subsection{Les résaux de neurones}
Une couche de neurones d’entrées, plusieurs couches cachées, une couche de sortie suivie d’une fonction d’activation.
Chaque neurone possède une valeur obtenue par une fonction de combinaison étant la somme des valeurs des neurones de la couche précédente, chacune multipliée par un poids spécifique
$ z = x_1 \cdot p_1 + x_2 \cdot p_2 + \cdots + x_n \cdot p_n $ \\
Une fois la (ou les) valeur de la couche de sortie obtenue, on applique à celle-ci une fonction d’activation qui transforme la valeur en fonction d’un seuil. Si en dessous du seuil, inactif (0/-1), aux environs du seuil, phase de transition, et au-dessus du seuil, actif (1/$>$1). Le type de fonction varie d’un cas à l’autre, mais les plus récurrentes sont la fonction sigmoïde $ \frac{1}{1 + e^{-x}}$ la fonction tangente hyperbolique $ \frac{2} {1 + e^{-2x}} -1 $
ou encore la fonction ReLU $\begin{cases} 0 & x < 0 \\ x & x >= 0 \end{cases}$ \\
Durant l’apprentissage, les poids sont des valeurs prises au hasard. Il faut donc les ajuster pour fournir une réponse qui se rapproche au mieux de la réalité. Comme on entraîne notre réseau, on connaît la vraie valeur finale. On va donc appliquer une fonction de coût afin de calculer le gradient d’erreur entre la valeur réelle et la valeur prédite $ \frac{1}{2}(y_r - y_p)^2 $, et ainsi mettre à jour les poids par rétropropagation (! il y a des maths plus compliquées derrière). A chaque nouvelles données injectées lors de l’apprentissage, le réseau est plus performant.

\subsection{Intro au langage Python}
\begin{enumerate}
  \item Créé par Guido van Rossum au Stichting Mathematisch Centrum en Hollande.
  \item Python est le successeur d’un langage de programmation nommé “ABC”
  \item Le nom du langage vient de la série Monty Python’s flying Circus dont Guido Van Rossum était fan. Cependant l’image du serpent paraissait plus évidente pour tout le monde, il a donc décidé d’utiliser celle-ci comme symbole du langage.
  \item La première version de Python paraissait en 1991
  \item C’est un langage de programmation open source, c’est à dire gratuit et libre d’utilisation
\end{enumerate}
\end{document}
